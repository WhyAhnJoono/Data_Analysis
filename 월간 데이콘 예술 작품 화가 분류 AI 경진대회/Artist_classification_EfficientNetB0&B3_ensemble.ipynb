{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "659a4148",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T08:26:11.574283Z",
     "start_time": "2022-11-08T08:26:09.820138Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import warnings\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d341622c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T08:26:11.578010Z",
     "start_time": "2022-11-08T08:26:11.576026Z"
    }
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "809f5a70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T08:26:11.641549Z",
     "start_time": "2022-11-08T08:26:11.578987Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 08:26:11.630641: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-08 08:26:11.634433: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-08 08:26:11.634992: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e77c8a5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T08:26:11.644969Z",
     "start_time": "2022-11-08T08:26:11.642905Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max.colwidth', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b830174",
   "metadata": {},
   "source": [
    "## Path Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "161477e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T08:26:13.099771Z",
     "start_time": "2022-11-08T08:26:13.097289Z"
    }
   },
   "outputs": [],
   "source": [
    "base_path = \"/data/data/05_DACON/Artist/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04d70ae",
   "metadata": {},
   "source": [
    "## Import DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03ccd4df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T08:26:14.815153Z",
     "start_time": "2022-11-08T08:26:14.735457Z"
    }
   },
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(os.path.join(base_path, \"train.csv\"), encoding='CP949')\n",
    "test_csv = pd.read_csv(os.path.join(base_path, \"test.csv\"), encoding='CP949')\n",
    "submisson = pd.read_csv(os.path.join(base_path, \"sample_submission.csv\"), encoding='CP949')\n",
    "art_info = pd.read_csv(os.path.join(base_path, \"artists_info.csv\"))\n",
    "df_merge = pd.read_csv(os.path.join(base_path, \"df_merge_raw_2_4.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54457a87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T08:26:14.870455Z",
     "start_time": "2022-11-08T08:26:14.863833Z"
    }
   },
   "outputs": [],
   "source": [
    "# 경로 변경\n",
    "df_merge['img_slice_re_path'] = base_path + '/train_raw_2_4/' + df_merge['img_slice_path'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4822234f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T08:26:14.992523Z",
     "start_time": "2022-11-08T08:26:14.984928Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img_path</th>\n",
       "      <th>artist</th>\n",
       "      <th>years</th>\n",
       "      <th>genre</th>\n",
       "      <th>nationality</th>\n",
       "      <th>re_img_path</th>\n",
       "      <th>img_slice_path</th>\n",
       "      <th>img_slice_re_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>./train/0000.jpg</td>\n",
       "      <td>Diego Velazquez</td>\n",
       "      <td>1599 - 1660</td>\n",
       "      <td>Baroque</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>/data/data/05_DACON/Artist/data/train/0000.jpg</td>\n",
       "      <td>0000.jpg</td>\n",
       "      <td>/data/data/05_DACON/Artist/data/train_raw_2_4/0000.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>./train/0000.jpg</td>\n",
       "      <td>Diego Velazquez</td>\n",
       "      <td>1599 - 1660</td>\n",
       "      <td>Baroque</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>/data/data/05_DACON/Artist/data/train/0000.jpg</td>\n",
       "      <td>0000_slice2_01_01.jpg</td>\n",
       "      <td>/data/data/05_DACON/Artist/data/train_raw_2_4/0000_slice2_01_01.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>./train/0000.jpg</td>\n",
       "      <td>Diego Velazquez</td>\n",
       "      <td>1599 - 1660</td>\n",
       "      <td>Baroque</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>/data/data/05_DACON/Artist/data/train/0000.jpg</td>\n",
       "      <td>0000_slice2_01_02.jpg</td>\n",
       "      <td>/data/data/05_DACON/Artist/data/train_raw_2_4/0000_slice2_01_02.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>./train/0000.jpg</td>\n",
       "      <td>Diego Velazquez</td>\n",
       "      <td>1599 - 1660</td>\n",
       "      <td>Baroque</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>/data/data/05_DACON/Artist/data/train/0000.jpg</td>\n",
       "      <td>0000_slice_01_01.jpg</td>\n",
       "      <td>/data/data/05_DACON/Artist/data/train_raw_2_4/0000_slice_01_01.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>./train/0000.jpg</td>\n",
       "      <td>Diego Velazquez</td>\n",
       "      <td>1599 - 1660</td>\n",
       "      <td>Baroque</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>/data/data/05_DACON/Artist/data/train/0000.jpg</td>\n",
       "      <td>0000_slice_01_02.jpg</td>\n",
       "      <td>/data/data/05_DACON/Artist/data/train_raw_2_4/0000_slice_01_02.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id          img_path           artist        years    genre nationality  \\\n",
       "0   0  ./train/0000.jpg  Diego Velazquez  1599 - 1660  Baroque     Spanish   \n",
       "1   0  ./train/0000.jpg  Diego Velazquez  1599 - 1660  Baroque     Spanish   \n",
       "2   0  ./train/0000.jpg  Diego Velazquez  1599 - 1660  Baroque     Spanish   \n",
       "3   0  ./train/0000.jpg  Diego Velazquez  1599 - 1660  Baroque     Spanish   \n",
       "4   0  ./train/0000.jpg  Diego Velazquez  1599 - 1660  Baroque     Spanish   \n",
       "\n",
       "                                      re_img_path         img_slice_path  \\\n",
       "0  /data/data/05_DACON/Artist/data/train/0000.jpg               0000.jpg   \n",
       "1  /data/data/05_DACON/Artist/data/train/0000.jpg  0000_slice2_01_01.jpg   \n",
       "2  /data/data/05_DACON/Artist/data/train/0000.jpg  0000_slice2_01_02.jpg   \n",
       "3  /data/data/05_DACON/Artist/data/train/0000.jpg   0000_slice_01_01.jpg   \n",
       "4  /data/data/05_DACON/Artist/data/train/0000.jpg   0000_slice_01_02.jpg   \n",
       "\n",
       "                                                     img_slice_re_path  \n",
       "0               /data/data/05_DACON/Artist/data/train_raw_2_4/0000.jpg  \n",
       "1  /data/data/05_DACON/Artist/data/train_raw_2_4/0000_slice2_01_01.jpg  \n",
       "2  /data/data/05_DACON/Artist/data/train_raw_2_4/0000_slice2_01_02.jpg  \n",
       "3   /data/data/05_DACON/Artist/data/train_raw_2_4/0000_slice_01_01.jpg  \n",
       "4   /data/data/05_DACON/Artist/data/train_raw_2_4/0000_slice_01_02.jpg  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d476d3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T08:26:15.149949Z",
     "start_time": "2022-11-08T08:26:15.144844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train artist count :  50\n"
     ]
    }
   ],
   "source": [
    "print(\"train artist count : \", len(df_merge['artist'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97ff84ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T08:26:15.259192Z",
     "start_time": "2022-11-08T08:26:15.250380Z"
    }
   },
   "outputs": [],
   "source": [
    "# 경로 변경\n",
    "test_csv['re_img_path'] =  [ x.replace('./test/', base_path+'/test/') for x in test_csv['img_path'] ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a507f8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T08:26:15.398512Z",
     "start_time": "2022-11-08T08:26:15.393387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img_path</th>\n",
       "      <th>re_img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00000</td>\n",
       "      <td>./test/TEST_00000.jpg</td>\n",
       "      <td>/data/data/05_DACON/Artist/data/test/TEST_00000.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00001</td>\n",
       "      <td>./test/TEST_00001.jpg</td>\n",
       "      <td>/data/data/05_DACON/Artist/data/test/TEST_00001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00002</td>\n",
       "      <td>./test/TEST_00002.jpg</td>\n",
       "      <td>/data/data/05_DACON/Artist/data/test/TEST_00002.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_00003</td>\n",
       "      <td>./test/TEST_00003.jpg</td>\n",
       "      <td>/data/data/05_DACON/Artist/data/test/TEST_00003.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_00004</td>\n",
       "      <td>./test/TEST_00004.jpg</td>\n",
       "      <td>/data/data/05_DACON/Artist/data/test/TEST_00004.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id               img_path  \\\n",
       "0  TEST_00000  ./test/TEST_00000.jpg   \n",
       "1  TEST_00001  ./test/TEST_00001.jpg   \n",
       "2  TEST_00002  ./test/TEST_00002.jpg   \n",
       "3  TEST_00003  ./test/TEST_00003.jpg   \n",
       "4  TEST_00004  ./test/TEST_00004.jpg   \n",
       "\n",
       "                                           re_img_path  \n",
       "0  /data/data/05_DACON/Artist/data/test/TEST_00000.jpg  \n",
       "1  /data/data/05_DACON/Artist/data/test/TEST_00001.jpg  \n",
       "2  /data/data/05_DACON/Artist/data/test/TEST_00002.jpg  \n",
       "3  /data/data/05_DACON/Artist/data/test/TEST_00003.jpg  \n",
       "4  /data/data/05_DACON/Artist/data/test/TEST_00004.jpg  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34af59d",
   "metadata": {
    "id": "xtRxwr1wtGbn"
   },
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcf56dc",
   "metadata": {
    "id": "pjP9Hoq5t6Jm"
   },
   "source": [
    "## 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76662766",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T08:26:15.863348Z",
     "start_time": "2022-11-08T08:26:15.861179Z"
    },
    "executionInfo": {
     "elapsed": 283,
     "status": "ok",
     "timestamp": 1665571567130,
     "user": {
      "displayName": "김영진",
      "userId": "12295710059356166575"
     },
     "user_tz": -540
    },
    "id": "fnxj-rnEt8TU"
   },
   "outputs": [],
   "source": [
    "# def show_grid_images(image_path_list, ncols=6):\n",
    "#     figure, axs = plt.subplots(figsize=(22, 6), nrows=1, ncols=ncols)\n",
    "#     for i in range(ncols):\n",
    "#       image = cv2.cvtColor(cv2.imread(image_path_list[i]), cv2.COLOR_BGR2RGB)\n",
    "#       axs[i].set_title(image_path_list[i][-8:])\n",
    "#       axs[i].imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ffb2c39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T06:46:41.033432Z",
     "start_time": "2022-11-07T06:46:41.031685Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1VG69nJTf-eY4obf6nSAMTqSmsgAnYxt5"
    },
    "executionInfo": {
     "elapsed": 149274,
     "status": "ok",
     "timestamp": 1665548326183,
     "user": {
      "displayName": "김영진",
      "userId": "12295710059356166575"
     },
     "user_tz": -540
    },
    "id": "eGiq66YvKwQo",
    "outputId": "2c214b0b-f63c-46e5-f5f5-b9623ef3ca92"
   },
   "outputs": [],
   "source": [
    "# artist별 image\n",
    "# artist_list = list(df_merge['artist'].value_counts().index)\n",
    "# for art in artist_list :\n",
    "#   show_grid_images(df_merge[df_merge[\"artist\"] == art ][\"re_img_path\"].values[:6])\n",
    "#   print(art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3067a542",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T06:46:41.038500Z",
     "start_time": "2022-11-07T06:46:41.036750Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1zzn0ZoX5b-jKxbgzT-OAdwv1wBgT0sFj"
    },
    "executionInfo": {
     "elapsed": 110764,
     "status": "ok",
     "timestamp": 1665571899130,
     "user": {
      "displayName": "김영진",
      "userId": "12295710059356166575"
     },
     "user_tz": -540
    },
    "id": "u5b0A9USzqqS",
    "outputId": "52bd4833-cf83-4793-8e41-bc2c21b75d48"
   },
   "outputs": [],
   "source": [
    "# genre별 image\n",
    "# genre_list = list(df_merge['genre'].value_counts().index)\n",
    "# for genre in genre_list :\n",
    "#   show_grid_images(df_merge[df_merge[\"genre\"] == genre ][\"re_img_path\"].values[:6])\n",
    "#   print(genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d2c7bfc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T06:46:41.041942Z",
     "start_time": "2022-11-07T06:46:41.040000Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1TLC86WJIOGmpUDrSAXzA3KVYjssTL4l1"
    },
    "executionInfo": {
     "elapsed": 35327,
     "status": "ok",
     "timestamp": 1665572028540,
     "user": {
      "displayName": "김영진",
      "userId": "12295710059356166575"
     },
     "user_tz": -540
    },
    "id": "rbhfoM7ezqoR",
    "outputId": "a98dc299-eaff-4247-ae1d-ab906e77af57"
   },
   "outputs": [],
   "source": [
    "# nationality별 image\n",
    "# nationality_list = list(df_merge['nationality'].value_counts().index)\n",
    "# for nat in nationality_list :\n",
    "#   show_grid_images(df_merge[df_merge[\"nationality\"] == nat ][\"re_img_path\"].values[:6])\n",
    "#   print(nat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c871e3d",
   "metadata": {},
   "source": [
    "## Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b0e33d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T08:26:20.164783Z",
     "start_time": "2022-11-08T08:26:20.162147Z"
    }
   },
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE':300,\n",
    "    'EPOCHS':50,\n",
    "    'LEARNING_RATE':5e-4,\n",
    "    'BATCH_SIZE':32,\n",
    "    'SEED':42,\n",
    "    'VALIDATION_SPLIT' : 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92eae49e",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fc4c684",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T08:26:20.677308Z",
     "start_time": "2022-11-08T08:26:20.674370Z"
    }
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    #rescale=1./255,\n",
    "    validation_split=CFG['VALIDATION_SPLIT'],\n",
    "    zoom_range = [0.5,1],\n",
    "#     horizontal_flip=True,\n",
    "#     vertical_flip=True,    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9db25587",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T08:26:21.335310Z",
     "start_time": "2022-11-08T08:26:21.083927Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41377 validated image filenames belonging to 50 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Albrecht Du rer': 0,\n",
       " 'Alfred Sisley': 1,\n",
       " 'Amedeo Modigliani': 2,\n",
       " 'Andrei Rublev': 3,\n",
       " 'Andy Warhol': 4,\n",
       " 'Camille Pissarro': 5,\n",
       " 'Caravaggio': 6,\n",
       " 'Claude Monet': 7,\n",
       " 'Diego Rivera': 8,\n",
       " 'Diego Velazquez': 9,\n",
       " 'Edgar Degas': 10,\n",
       " 'Edouard Manet': 11,\n",
       " 'Edvard Munch': 12,\n",
       " 'El Greco': 13,\n",
       " 'Eugene Delacroix': 14,\n",
       " 'Francisco Goya': 15,\n",
       " 'Frida Kahlo': 16,\n",
       " 'Georges Seurat': 17,\n",
       " 'Giotto di Bondone': 18,\n",
       " 'Gustav Klimt': 19,\n",
       " 'Gustave Courbet': 20,\n",
       " 'Henri Matisse': 21,\n",
       " 'Henri Rousseau': 22,\n",
       " 'Henri de Toulouse-Lautrec': 23,\n",
       " 'Hieronymus Bosch': 24,\n",
       " 'Jackson Pollock': 25,\n",
       " 'Jan van Eyck': 26,\n",
       " 'Joan Miro': 27,\n",
       " 'Kazimir Malevich': 28,\n",
       " 'Leonardo da Vinci': 29,\n",
       " 'Marc Chagall': 30,\n",
       " 'Michelangelo': 31,\n",
       " 'Mikhail Vrubel': 32,\n",
       " 'Pablo Picasso': 33,\n",
       " 'Paul Cezanne': 34,\n",
       " 'Paul Gauguin': 35,\n",
       " 'Paul Klee': 36,\n",
       " 'Peter Paul Rubens': 37,\n",
       " 'Pierre-Auguste Renoir': 38,\n",
       " 'Piet Mondrian': 39,\n",
       " 'Pieter Bruegel': 40,\n",
       " 'Raphael': 41,\n",
       " 'Rembrandt': 42,\n",
       " 'Rene Magritte': 43,\n",
       " 'Salvador Dali': 44,\n",
       " 'Sandro Botticelli': 45,\n",
       " 'Titian': 46,\n",
       " 'Vasiliy Kandinskiy': 47,\n",
       " 'Vincent van Gogh': 48,\n",
       " 'William Turner': 49}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen = datagen.flow_from_dataframe(df_merge, x_col='img_slice_re_path', y_col='artist', target_size=(CFG['IMG_SIZE'],CFG['IMG_SIZE']), batch_size=CFG['BATCH_SIZE'], seed=CFG['SEED'])\n",
    "train_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "638bf07a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T08:26:23.061597Z",
     "start_time": "2022-11-08T08:26:22.927446Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, make_scorer, confusion_matrix, accuracy_score, precision_score, recall_score, precision_recall_curve\n",
    "from keras import backend as K\n",
    "def recall(y_target, y_pred):\n",
    "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "    # round : 반올림한다\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "\n",
    "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
    "\n",
    "    # (True Positive + False Negative) = 실제 값이 1(Positive) 전체\n",
    "    count_true_positive_false_negative = K.sum(y_target_yn)\n",
    "\n",
    "    # Recall =  (True Positive) / (True Positive + False Negative)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
    "\n",
    "    # return a single tensor value\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision(y_target, y_pred):\n",
    "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "    # round : 반올림한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "\n",
    "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
    "\n",
    "    # (True Positive + False Positive) = 예측 값이 1(Positive) 전체\n",
    "    count_true_positive_false_positive = K.sum(y_pred_yn)\n",
    "\n",
    "    # Precision = (True Positive) / (True Positive + False Positive)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    precision = count_true_positive / (count_true_positive_false_positive + K.epsilon())\n",
    "\n",
    "    # return a single tensor value\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1score(y_target, y_pred):\n",
    "    _recall = recall(y_target, y_pred)\n",
    "    _precision = precision(y_target, y_pred)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    _f1score = ( 2 * _recall * _precision) / (_recall + _precision+ K.epsilon())\n",
    "    \n",
    "    # return a single tensor value\n",
    "    return _f1score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190126f8",
   "metadata": {},
   "source": [
    "## Modeling(ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d14efb3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T08:26:24.243670Z",
     "start_time": "2022-11-08T08:26:24.157907Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "import albumentations as al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7902564",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T06:46:41.530663Z",
     "start_time": "2022-11-07T06:46:41.523139Z"
    }
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3, shuffle=True,random_state=CFG['SEED']) # 3 Fold Validation\n",
    "\n",
    "def EfficientNetB3_model():\n",
    "\n",
    "    for fold_var, (train_index, valid_index) in enumerate(kf.split(df_merge, df_merge['artist']), 1) :\n",
    "\n",
    "        x_train = df_merge.iloc[train_index]\n",
    "        x_valid = df_merge.iloc[valid_index]\n",
    "        train_gen = datagen.flow_from_dataframe(x_train, x_col='img_slice_re_path', y_col='artist', target_size=(CFG['IMG_SIZE'],CFG['IMG_SIZE']), batch_size=CFG['BATCH_SIZE'], seed=CFG['SEED'])\n",
    "        valid_gen = datagen.flow_from_dataframe(x_valid, x_col='img_slice_re_path', y_col='artist', target_size=(CFG['IMG_SIZE'],CFG['IMG_SIZE']), batch_size=CFG['BATCH_SIZE'], seed=CFG['SEED']) \n",
    "        # 대부분은 vaildset에 augment를 적용하지 않지만, 대부분의 이미지들이 이미 rotate, filp등이 적용된 상태였고, ReduceLROnPlateau로 적절한 시점에서의 lr 조정을 위해 실험해본 결과 지금과 같이 단순한 90도 rotation 적용은 최종 정확도에 약간의 긍정적인 영향을 주었기에 이를 적용하였습니다.\n",
    "        # 최종 평가 학습 부분에서는 90도 회전이 아닌 -90도~90도까지의 다양한 각도 회전 augmentation을 적용하였기에 분명히 augmentation을 적용하지 않았어야 했는데 이 부분을 수정하지 않아 문제가 되었습니다\n",
    "        tf.random.set_seed(CFG['SEED'])\n",
    "        input_tensor = Input(shape=(CFG['IMG_SIZE'], CFG['IMG_SIZE'], 3))  \n",
    "\n",
    "        base_model = EfficientNetB3(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
    "        base_model.trainable = True # 재학습 여부\n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "#         x = Dense(512, activation='relu')(x)\n",
    "#         x = Dense(256, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        output = Dense(50, activation='softmax')(x)\n",
    "        model = Model(inputs=input_tensor, outputs=output)\n",
    "\n",
    "        model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics = [f1score, 'acc']) # Adam lr = 0.001(default)\n",
    "        es = EarlyStopping(patience=10, restore_best_weights=True, verbose=1) \n",
    "        rl = ReduceLROnPlateau(patience=5, verbose=1, factor=0.5, min_lr=1e-5) \n",
    "        cb = ModelCheckpoint(filepath=base_path + '/fold{}_EfficientNetB3_raw_2_4_best_221107.h5'.format(str(fold_var)), save_best_only=True, exist_ok=True, verbose=1)\n",
    "        model.fit(train_gen, validation_data=valid_gen, epochs=CFG['EPOCHS'], callbacks=[es,cb,rl]) \n",
    "\n",
    "    K.clear_session()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84263021",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T04:27:23.285652Z",
     "start_time": "2022-11-07T06:46:41.532174Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27584 validated image filenames belonging to 50 classes.\n",
      "Found 13793 validated image filenames belonging to 50 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 06:46:41.883263: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-07 06:46:41.884638: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-07 06:46:41.885255: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-07 06:46:41.885802: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-07 06:46:42.208257: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-07 06:46:42.208787: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-07 06:46:42.209281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-07 06:46:42.209751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21936 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:09:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 06:46:53.158024: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n",
      "2022-11-07 06:46:54.444470: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "862/862 [==============================] - ETA: 0s - loss: 1.7375 - f1score: 0.4851 - acc: 0.5284\n",
      "Epoch 1: val_loss improved from inf to 1.47076, saving model to /data/data/05_DACON/Artist/data/fold1_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "862/862 [==============================] - 715s 817ms/step - loss: 1.7375 - f1score: 0.4851 - acc: 0.5284 - val_loss: 1.4708 - val_f1score: 0.5944 - val_acc: 0.5978 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 1.0557 - f1score: 0.6903 - acc: 0.6963\n",
      "Epoch 2: val_loss improved from 1.47076 to 1.25762, saving model to /data/data/05_DACON/Artist/data/fold1_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "862/862 [==============================] - 495s 574ms/step - loss: 1.0557 - f1score: 0.6903 - acc: 0.6963 - val_loss: 1.2576 - val_f1score: 0.6542 - val_acc: 0.6463 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.8119 - f1score: 0.7591 - acc: 0.7593\n",
      "Epoch 3: val_loss did not improve from 1.25762\n",
      "862/862 [==============================] - 522s 605ms/step - loss: 0.8119 - f1score: 0.7591 - acc: 0.7593 - val_loss: 1.3271 - val_f1score: 0.6681 - val_acc: 0.6606 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.6768 - f1score: 0.7973 - acc: 0.7949\n",
      "Epoch 4: val_loss improved from 1.25762 to 0.88187, saving model to /data/data/05_DACON/Artist/data/fold1_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "862/862 [==============================] - 523s 607ms/step - loss: 0.6768 - f1score: 0.7973 - acc: 0.7949 - val_loss: 0.8819 - val_f1score: 0.7524 - val_acc: 0.7457 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.5769 - f1score: 0.8266 - acc: 0.8244\n",
      "Epoch 5: val_loss improved from 0.88187 to 0.75575, saving model to /data/data/05_DACON/Artist/data/fold1_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "862/862 [==============================] - 524s 608ms/step - loss: 0.5769 - f1score: 0.8266 - acc: 0.8244 - val_loss: 0.7557 - val_f1score: 0.7915 - val_acc: 0.7890 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.5048 - f1score: 0.8479 - acc: 0.8449\n",
      "Epoch 6: val_loss did not improve from 0.75575\n",
      "862/862 [==============================] - 523s 607ms/step - loss: 0.5048 - f1score: 0.8479 - acc: 0.8449 - val_loss: 0.8626 - val_f1score: 0.7741 - val_acc: 0.7676 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.4471 - f1score: 0.8642 - acc: 0.8616\n",
      "Epoch 7: val_loss did not improve from 0.75575\n",
      "862/862 [==============================] - 522s 606ms/step - loss: 0.4471 - f1score: 0.8642 - acc: 0.8616 - val_loss: 1.3315 - val_f1score: 0.6915 - val_acc: 0.6807 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.4126 - f1score: 0.8760 - acc: 0.8735\n",
      "Epoch 8: val_loss improved from 0.75575 to 0.69477, saving model to /data/data/05_DACON/Artist/data/fold1_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "862/862 [==============================] - 522s 606ms/step - loss: 0.4126 - f1score: 0.8760 - acc: 0.8735 - val_loss: 0.6948 - val_f1score: 0.8124 - val_acc: 0.8080 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.3675 - f1score: 0.8891 - acc: 0.8877\n",
      "Epoch 9: val_loss improved from 0.69477 to 0.60795, saving model to /data/data/05_DACON/Artist/data/fold1_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "862/862 [==============================] - 522s 606ms/step - loss: 0.3675 - f1score: 0.8891 - acc: 0.8877 - val_loss: 0.6080 - val_f1score: 0.8358 - val_acc: 0.8289 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.3299 - f1score: 0.9008 - acc: 0.8994\n",
      "Epoch 10: val_loss did not improve from 0.60795\n",
      "862/862 [==============================] - 518s 601ms/step - loss: 0.3299 - f1score: 0.9008 - acc: 0.8994 - val_loss: 0.7316 - val_f1score: 0.8110 - val_acc: 0.8065 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.3205 - f1score: 0.9022 - acc: 0.9000\n",
      "Epoch 11: val_loss did not improve from 0.60795\n",
      "862/862 [==============================] - 521s 604ms/step - loss: 0.3205 - f1score: 0.9022 - acc: 0.9000 - val_loss: 0.9009 - val_f1score: 0.7779 - val_acc: 0.7721 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.2982 - f1score: 0.9085 - acc: 0.9067\n",
      "Epoch 12: val_loss did not improve from 0.60795\n",
      "862/862 [==============================] - 521s 604ms/step - loss: 0.2982 - f1score: 0.9085 - acc: 0.9067 - val_loss: 0.8168 - val_f1score: 0.7935 - val_acc: 0.7879 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.2745 - f1score: 0.9163 - acc: 0.9156\n",
      "Epoch 13: val_loss did not improve from 0.60795\n",
      "862/862 [==============================] - 522s 605ms/step - loss: 0.2745 - f1score: 0.9163 - acc: 0.9156 - val_loss: 0.7053 - val_f1score: 0.8233 - val_acc: 0.8154 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.2638 - f1score: 0.9188 - acc: 0.9165\n",
      "Epoch 14: val_loss did not improve from 0.60795\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "862/862 [==============================] - 521s 604ms/step - loss: 0.2638 - f1score: 0.9188 - acc: 0.9165 - val_loss: 3.4014 - val_f1score: 0.8143 - val_acc: 0.8077 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.1284 - f1score: 0.9603 - acc: 0.9600\n",
      "Epoch 15: val_loss improved from 0.60795 to 0.30965, saving model to /data/data/05_DACON/Artist/data/fold1_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "862/862 [==============================] - 523s 606ms/step - loss: 0.1284 - f1score: 0.9603 - acc: 0.9600 - val_loss: 0.3096 - val_f1score: 0.9173 - val_acc: 0.9139 - lr: 5.0000e-04\n",
      "Epoch 16/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.0946 - f1score: 0.9715 - acc: 0.9705\n",
      "Epoch 16: val_loss did not improve from 0.30965\n",
      "862/862 [==============================] - 516s 598ms/step - loss: 0.0946 - f1score: 0.9715 - acc: 0.9705 - val_loss: 0.5447 - val_f1score: 0.8978 - val_acc: 0.8934 - lr: 5.0000e-04\n",
      "Epoch 17/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.0958 - f1score: 0.9698 - acc: 0.9694\n",
      "Epoch 17: val_loss did not improve from 0.30965\n",
      "862/862 [==============================] - 519s 602ms/step - loss: 0.0958 - f1score: 0.9698 - acc: 0.9694 - val_loss: 0.3476 - val_f1score: 0.9109 - val_acc: 0.9074 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.0933 - f1score: 0.9699 - acc: 0.9693\n",
      "Epoch 18: val_loss did not improve from 0.30965\n",
      "862/862 [==============================] - 521s 604ms/step - loss: 0.0933 - f1score: 0.9699 - acc: 0.9693 - val_loss: 1.4077 - val_f1score: 0.8979 - val_acc: 0.8949 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.0883 - f1score: 0.9715 - acc: 0.9714\n",
      "Epoch 19: val_loss did not improve from 0.30965\n",
      "862/862 [==============================] - 517s 599ms/step - loss: 0.0883 - f1score: 0.9715 - acc: 0.9714 - val_loss: 0.4904 - val_f1score: 0.8948 - val_acc: 0.8949 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.0879 - f1score: 0.9726 - acc: 0.9722\n",
      "Epoch 20: val_loss did not improve from 0.30965\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "862/862 [==============================] - 517s 599ms/step - loss: 0.0879 - f1score: 0.9726 - acc: 0.9722 - val_loss: 0.3538 - val_f1score: 0.9140 - val_acc: 0.9095 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.0475 - f1score: 0.9856 - acc: 0.9858\n",
      "Epoch 21: val_loss improved from 0.30965 to 0.25236, saving model to /data/data/05_DACON/Artist/data/fold1_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "862/862 [==============================] - 520s 603ms/step - loss: 0.0475 - f1score: 0.9856 - acc: 0.9858 - val_loss: 0.2524 - val_f1score: 0.9390 - val_acc: 0.9362 - lr: 2.5000e-04\n",
      "Epoch 22/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.0368 - f1score: 0.9889 - acc: 0.9890\n",
      "Epoch 22: val_loss did not improve from 0.25236\n",
      "862/862 [==============================] - 523s 606ms/step - loss: 0.0368 - f1score: 0.9889 - acc: 0.9890 - val_loss: 0.2997 - val_f1score: 0.9280 - val_acc: 0.9255 - lr: 2.5000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.0351 - f1score: 0.9889 - acc: 0.9892\n",
      "Epoch 23: val_loss improved from 0.25236 to 0.24178, saving model to /data/data/05_DACON/Artist/data/fold1_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "862/862 [==============================] - 521s 604ms/step - loss: 0.0351 - f1score: 0.9889 - acc: 0.9892 - val_loss: 0.2418 - val_f1score: 0.9376 - val_acc: 0.9383 - lr: 2.5000e-04\n",
      "Epoch 24/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.0348 - f1score: 0.9889 - acc: 0.9888\n",
      "Epoch 24: val_loss did not improve from 0.24178\n",
      "862/862 [==============================] - 520s 603ms/step - loss: 0.0348 - f1score: 0.9889 - acc: 0.9888 - val_loss: 0.2615 - val_f1score: 0.9350 - val_acc: 0.9325 - lr: 2.5000e-04\n",
      "Epoch 25/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.0300 - f1score: 0.9902 - acc: 0.9902\n",
      "Epoch 25: val_loss did not improve from 0.24178\n",
      "862/862 [==============================] - 516s 599ms/step - loss: 0.0300 - f1score: 0.9902 - acc: 0.9902 - val_loss: 0.2604 - val_f1score: 0.9382 - val_acc: 0.9357 - lr: 2.5000e-04\n",
      "Epoch 26/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.0289 - f1score: 0.9912 - acc: 0.9912\n",
      "Epoch 26: val_loss did not improve from 0.24178\n",
      "862/862 [==============================] - 523s 607ms/step - loss: 0.0289 - f1score: 0.9912 - acc: 0.9912 - val_loss: 0.2760 - val_f1score: 0.9347 - val_acc: 0.9327 - lr: 2.5000e-04\n",
      "Epoch 27/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.0327 - f1score: 0.9898 - acc: 0.9896\n",
      "Epoch 27: val_loss did not improve from 0.24178\n",
      "862/862 [==============================] - 520s 603ms/step - loss: 0.0327 - f1score: 0.9898 - acc: 0.9896 - val_loss: 0.2843 - val_f1score: 0.9342 - val_acc: 0.9321 - lr: 2.5000e-04\n",
      "Epoch 28/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.0335 - f1score: 0.9890 - acc: 0.9888\n",
      "Epoch 28: val_loss did not improve from 0.24178\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "862/862 [==============================] - 521s 605ms/step - loss: 0.0335 - f1score: 0.9890 - acc: 0.9888 - val_loss: 0.2672 - val_f1score: 0.9370 - val_acc: 0.9352 - lr: 2.5000e-04\n",
      "Epoch 29/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.0202 - f1score: 0.9936 - acc: 0.9935\n",
      "Epoch 29: val_loss improved from 0.24178 to 0.22383, saving model to /data/data/05_DACON/Artist/data/fold1_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "862/862 [==============================] - 520s 603ms/step - loss: 0.0202 - f1score: 0.9936 - acc: 0.9935 - val_loss: 0.2238 - val_f1score: 0.9449 - val_acc: 0.9429 - lr: 1.2500e-04\n",
      "Epoch 30/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.0155 - f1score: 0.9949 - acc: 0.9950\n",
      "Epoch 30: val_loss improved from 0.22383 to 0.22002, saving model to /data/data/05_DACON/Artist/data/fold1_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "862/862 [==============================] - 522s 606ms/step - loss: 0.0155 - f1score: 0.9949 - acc: 0.9950 - val_loss: 0.2200 - val_f1score: 0.9478 - val_acc: 0.9457 - lr: 1.2500e-04\n",
      "Epoch 31/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.0129 - f1score: 0.9959 - acc: 0.9958\n",
      "Epoch 31: val_loss improved from 0.22002 to 0.21635, saving model to /data/data/05_DACON/Artist/data/fold1_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "862/862 [==============================] - 518s 600ms/step - loss: 0.0129 - f1score: 0.9959 - acc: 0.9958 - val_loss: 0.2164 - val_f1score: 0.9497 - val_acc: 0.9487 - lr: 1.2500e-04\n",
      "Epoch 32/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.0170 - f1score: 0.9946 - acc: 0.9946\n",
      "Epoch 32: val_loss did not improve from 0.21635\n",
      "862/862 [==============================] - 523s 606ms/step - loss: 0.0170 - f1score: 0.9946 - acc: 0.9946 - val_loss: 0.2240 - val_f1score: 0.9471 - val_acc: 0.9450 - lr: 1.2500e-04\n",
      "Epoch 33/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.0128 - f1score: 0.9961 - acc: 0.9960\n",
      "Epoch 33: val_loss did not improve from 0.21635\n",
      "862/862 [==============================] - 522s 605ms/step - loss: 0.0128 - f1score: 0.9961 - acc: 0.9960 - val_loss: 0.2179 - val_f1score: 0.9469 - val_acc: 0.9455 - lr: 1.2500e-04\n",
      "Epoch 34/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.0134 - f1score: 0.9959 - acc: 0.9958\n",
      "Epoch 34: val_loss did not improve from 0.21635\n",
      "862/862 [==============================] - 516s 598ms/step - loss: 0.0134 - f1score: 0.9959 - acc: 0.9958 - val_loss: 0.2317 - val_f1score: 0.9466 - val_acc: 0.9448 - lr: 1.2500e-04\n",
      "Epoch 35/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.0136 - f1score: 0.9960 - acc: 0.9959\n",
      "Epoch 35: val_loss did not improve from 0.21635\n",
      "862/862 [==============================] - 516s 599ms/step - loss: 0.0136 - f1score: 0.9960 - acc: 0.9959 - val_loss: 0.2361 - val_f1score: 0.9471 - val_acc: 0.9461 - lr: 1.2500e-04\n",
      "Epoch 36/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.0140 - f1score: 0.9956 - acc: 0.9956\n",
      "Epoch 36: val_loss did not improve from 0.21635\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "862/862 [==============================] - 515s 598ms/step - loss: 0.0140 - f1score: 0.9956 - acc: 0.9956 - val_loss: 0.2628 - val_f1score: 0.9493 - val_acc: 0.9479 - lr: 1.2500e-04\n",
      "Epoch 37/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.0095 - f1score: 0.9970 - acc: 0.9970\n",
      "Epoch 37: val_loss improved from 0.21635 to 0.21569, saving model to /data/data/05_DACON/Artist/data/fold1_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "862/862 [==============================] - 518s 601ms/step - loss: 0.0095 - f1score: 0.9970 - acc: 0.9970 - val_loss: 0.2157 - val_f1score: 0.9539 - val_acc: 0.9515 - lr: 6.2500e-05\n",
      "Epoch 38/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.0094 - f1score: 0.9971 - acc: 0.9972\n",
      "Epoch 38: val_loss improved from 0.21569 to 0.20602, saving model to /data/data/05_DACON/Artist/data/fold1_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "862/862 [==============================] - 515s 597ms/step - loss: 0.0094 - f1score: 0.9971 - acc: 0.9972 - val_loss: 0.2060 - val_f1score: 0.9523 - val_acc: 0.9506 - lr: 6.2500e-05\n",
      "Epoch 39/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.0082 - f1score: 0.9978 - acc: 0.9979\n",
      "Epoch 39: val_loss improved from 0.20602 to 0.19921, saving model to /data/data/05_DACON/Artist/data/fold1_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "862/862 [==============================] - 515s 597ms/step - loss: 0.0082 - f1score: 0.9978 - acc: 0.9979 - val_loss: 0.1992 - val_f1score: 0.9527 - val_acc: 0.9507 - lr: 6.2500e-05\n",
      "Epoch 40/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.0099 - f1score: 0.9969 - acc: 0.9971\n",
      "Epoch 40: val_loss improved from 0.19921 to 0.19786, saving model to /data/data/05_DACON/Artist/data/fold1_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "862/862 [==============================] - 517s 599ms/step - loss: 0.0099 - f1score: 0.9969 - acc: 0.9971 - val_loss: 0.1979 - val_f1score: 0.9542 - val_acc: 0.9527 - lr: 6.2500e-05\n",
      "Epoch 41/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.0073 - f1score: 0.9975 - acc: 0.9976\n",
      "Epoch 41: val_loss did not improve from 0.19786\n",
      "862/862 [==============================] - 521s 604ms/step - loss: 0.0073 - f1score: 0.9975 - acc: 0.9976 - val_loss: 0.2052 - val_f1score: 0.9541 - val_acc: 0.9529 - lr: 6.2500e-05\n",
      "Epoch 42/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.0068 - f1score: 0.9978 - acc: 0.9978\n",
      "Epoch 42: val_loss did not improve from 0.19786\n",
      "862/862 [==============================] - 520s 603ms/step - loss: 0.0068 - f1score: 0.9978 - acc: 0.9978 - val_loss: 0.2060 - val_f1score: 0.9537 - val_acc: 0.9529 - lr: 6.2500e-05\n",
      "Epoch 43/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.0061 - f1score: 0.9983 - acc: 0.9983\n",
      "Epoch 43: val_loss did not improve from 0.19786\n",
      "862/862 [==============================] - 519s 602ms/step - loss: 0.0061 - f1score: 0.9983 - acc: 0.9983 - val_loss: 0.2057 - val_f1score: 0.9544 - val_acc: 0.9519 - lr: 6.2500e-05\n",
      "Epoch 44/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.0062 - f1score: 0.9979 - acc: 0.9980\n",
      "Epoch 44: val_loss did not improve from 0.19786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "862/862 [==============================] - 523s 607ms/step - loss: 0.0062 - f1score: 0.9979 - acc: 0.9980 - val_loss: 0.2001 - val_f1score: 0.9566 - val_acc: 0.9552 - lr: 6.2500e-05\n",
      "Epoch 45/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.0062 - f1score: 0.9983 - acc: 0.9983\n",
      "Epoch 45: val_loss did not improve from 0.19786\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "862/862 [==============================] - 521s 605ms/step - loss: 0.0062 - f1score: 0.9983 - acc: 0.9983 - val_loss: 0.2045 - val_f1score: 0.9548 - val_acc: 0.9530 - lr: 6.2500e-05\n",
      "Epoch 46/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.0067 - f1score: 0.9980 - acc: 0.9979\n",
      "Epoch 46: val_loss did not improve from 0.19786\n",
      "862/862 [==============================] - 516s 599ms/step - loss: 0.0067 - f1score: 0.9980 - acc: 0.9979 - val_loss: 0.2042 - val_f1score: 0.9545 - val_acc: 0.9536 - lr: 3.1250e-05\n",
      "Epoch 47/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.0065 - f1score: 0.9978 - acc: 0.9980\n",
      "Epoch 47: val_loss improved from 0.19786 to 0.18944, saving model to /data/data/05_DACON/Artist/data/fold1_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "862/862 [==============================] - 514s 596ms/step - loss: 0.0065 - f1score: 0.9978 - acc: 0.9980 - val_loss: 0.1894 - val_f1score: 0.9562 - val_acc: 0.9545 - lr: 3.1250e-05\n",
      "Epoch 48/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.0045 - f1score: 0.9985 - acc: 0.9985\n",
      "Epoch 48: val_loss did not improve from 0.18944\n",
      "862/862 [==============================] - 520s 603ms/step - loss: 0.0045 - f1score: 0.9985 - acc: 0.9985 - val_loss: 0.1950 - val_f1score: 0.9570 - val_acc: 0.9553 - lr: 3.1250e-05\n",
      "Epoch 49/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.0052 - f1score: 0.9985 - acc: 0.9985\n",
      "Epoch 49: val_loss did not improve from 0.18944\n",
      "862/862 [==============================] - 514s 596ms/step - loss: 0.0052 - f1score: 0.9985 - acc: 0.9985 - val_loss: 0.1923 - val_f1score: 0.9592 - val_acc: 0.9576 - lr: 3.1250e-05\n",
      "Epoch 50/50\n",
      "862/862 [==============================] - ETA: 0s - loss: 0.0044 - f1score: 0.9984 - acc: 0.9985\n",
      "Epoch 50: val_loss did not improve from 0.18944\n",
      "862/862 [==============================] - 517s 600ms/step - loss: 0.0044 - f1score: 0.9984 - acc: 0.9985 - val_loss: 0.1919 - val_f1score: 0.9577 - val_acc: 0.9564 - lr: 3.1250e-05\n",
      "Found 27585 validated image filenames belonging to 50 classes.\n",
      "Found 13792 validated image filenames belonging to 50 classes.\n",
      "Epoch 1/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 1.7403 - f1score: 0.4809 - acc: 0.5232\n",
      "Epoch 1: val_loss improved from inf to 1.59197, saving model to /data/data/05_DACON/Artist/data/fold2_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "863/863 [==============================] - 529s 604ms/step - loss: 1.7403 - f1score: 0.4809 - acc: 0.5232 - val_loss: 1.5920 - val_f1score: 0.5730 - val_acc: 0.5750 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 1.0560 - f1score: 0.6884 - acc: 0.6936\n",
      "Epoch 2: val_loss improved from 1.59197 to 1.13803, saving model to /data/data/05_DACON/Artist/data/fold2_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "863/863 [==============================] - 518s 600ms/step - loss: 1.0560 - f1score: 0.6884 - acc: 0.6936 - val_loss: 1.1380 - val_f1score: 0.7077 - val_acc: 0.7003 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.8204 - f1score: 0.7557 - acc: 0.7551\n",
      "Epoch 3: val_loss improved from 1.13803 to 1.03035, saving model to /data/data/05_DACON/Artist/data/fold2_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "863/863 [==============================] - 521s 603ms/step - loss: 0.8204 - f1score: 0.7557 - acc: 0.7551 - val_loss: 1.0304 - val_f1score: 0.7179 - val_acc: 0.7108 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.6754 - f1score: 0.7965 - acc: 0.7947\n",
      "Epoch 4: val_loss did not improve from 1.03035\n",
      "863/863 [==============================] - 519s 601ms/step - loss: 0.6754 - f1score: 0.7965 - acc: 0.7947 - val_loss: 1.6252 - val_f1score: 0.6321 - val_acc: 0.6280 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.5737 - f1score: 0.8255 - acc: 0.8242\n",
      "Epoch 5: val_loss improved from 1.03035 to 0.71355, saving model to /data/data/05_DACON/Artist/data/fold2_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "863/863 [==============================] - 523s 606ms/step - loss: 0.5737 - f1score: 0.8255 - acc: 0.8242 - val_loss: 0.7135 - val_f1score: 0.7991 - val_acc: 0.7927 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.5174 - f1score: 0.8451 - acc: 0.8426\n",
      "Epoch 6: val_loss did not improve from 0.71355\n",
      "863/863 [==============================] - 520s 602ms/step - loss: 0.5174 - f1score: 0.8451 - acc: 0.8426 - val_loss: 0.8509 - val_f1score: 0.7801 - val_acc: 0.7725 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.4478 - f1score: 0.8634 - acc: 0.8637\n",
      "Epoch 7: val_loss did not improve from 0.71355\n",
      "863/863 [==============================] - 521s 603ms/step - loss: 0.4478 - f1score: 0.8634 - acc: 0.8637 - val_loss: 0.7452 - val_f1score: 0.7990 - val_acc: 0.7943 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.4091 - f1score: 0.8758 - acc: 0.8761\n",
      "Epoch 8: val_loss did not improve from 0.71355\n",
      "863/863 [==============================] - 513s 594ms/step - loss: 0.4091 - f1score: 0.8758 - acc: 0.8761 - val_loss: 0.8079 - val_f1score: 0.7913 - val_acc: 0.7840 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.3630 - f1score: 0.8890 - acc: 0.8875\n",
      "Epoch 9: val_loss did not improve from 0.71355\n",
      "863/863 [==============================] - 516s 597ms/step - loss: 0.3630 - f1score: 0.8890 - acc: 0.8875 - val_loss: 0.7651 - val_f1score: 0.8037 - val_acc: 0.7958 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.3452 - f1score: 0.8943 - acc: 0.8940\n",
      "Epoch 10: val_loss improved from 0.71355 to 0.66742, saving model to /data/data/05_DACON/Artist/data/fold2_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "863/863 [==============================] - 514s 595ms/step - loss: 0.3452 - f1score: 0.8943 - acc: 0.8940 - val_loss: 0.6674 - val_f1score: 0.8270 - val_acc: 0.8211 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.3231 - f1score: 0.8986 - acc: 0.8974\n",
      "Epoch 11: val_loss did not improve from 0.66742\n",
      "863/863 [==============================] - 513s 594ms/step - loss: 0.3231 - f1score: 0.8986 - acc: 0.8974 - val_loss: 0.7867 - val_f1score: 0.8116 - val_acc: 0.8072 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.2994 - f1score: 0.9077 - acc: 0.9066\n",
      "Epoch 12: val_loss did not improve from 0.66742\n",
      "863/863 [==============================] - 515s 597ms/step - loss: 0.2994 - f1score: 0.9077 - acc: 0.9066 - val_loss: 0.7335 - val_f1score: 0.8088 - val_acc: 0.8008 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.2766 - f1score: 0.9154 - acc: 0.9146\n",
      "Epoch 13: val_loss did not improve from 0.66742\n",
      "863/863 [==============================] - 512s 593ms/step - loss: 0.2766 - f1score: 0.9154 - acc: 0.9146 - val_loss: 0.7155 - val_f1score: 0.8206 - val_acc: 0.8134 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.2582 - f1score: 0.9168 - acc: 0.9164\n",
      "Epoch 14: val_loss did not improve from 0.66742\n",
      "863/863 [==============================] - 506s 586ms/step - loss: 0.2582 - f1score: 0.9168 - acc: 0.9164 - val_loss: 0.7543 - val_f1score: 0.8146 - val_acc: 0.8066 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.2511 - f1score: 0.9222 - acc: 0.9213\n",
      "Epoch 15: val_loss improved from 0.66742 to 0.65936, saving model to /data/data/05_DACON/Artist/data/fold2_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "863/863 [==============================] - 515s 596ms/step - loss: 0.2511 - f1score: 0.9222 - acc: 0.9213 - val_loss: 0.6594 - val_f1score: 0.8381 - val_acc: 0.8321 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.2379 - f1score: 0.9273 - acc: 0.9274\n",
      "Epoch 16: val_loss improved from 0.65936 to 0.64420, saving model to /data/data/05_DACON/Artist/data/fold2_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "863/863 [==============================] - 517s 599ms/step - loss: 0.2379 - f1score: 0.9273 - acc: 0.9274 - val_loss: 0.6442 - val_f1score: 0.8440 - val_acc: 0.8377 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.2260 - f1score: 0.9312 - acc: 0.9316\n",
      "Epoch 17: val_loss improved from 0.64420 to 0.58089, saving model to /data/data/05_DACON/Artist/data/fold2_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "863/863 [==============================] - 517s 598ms/step - loss: 0.2260 - f1score: 0.9312 - acc: 0.9316 - val_loss: 0.5809 - val_f1score: 0.8500 - val_acc: 0.8445 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.2104 - f1score: 0.9351 - acc: 0.9352\n",
      "Epoch 18: val_loss did not improve from 0.58089\n",
      "863/863 [==============================] - 513s 595ms/step - loss: 0.2104 - f1score: 0.9351 - acc: 0.9352 - val_loss: 0.6836 - val_f1score: 0.8369 - val_acc: 0.8314 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.2079 - f1score: 0.9347 - acc: 0.9342\n",
      "Epoch 19: val_loss did not improve from 0.58089\n",
      "863/863 [==============================] - 513s 594ms/step - loss: 0.2079 - f1score: 0.9347 - acc: 0.9342 - val_loss: 0.6655 - val_f1score: 0.8362 - val_acc: 0.8300 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.2096 - f1score: 0.9342 - acc: 0.9343\n",
      "Epoch 20: val_loss improved from 0.58089 to 0.57998, saving model to /data/data/05_DACON/Artist/data/fold2_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "863/863 [==============================] - 520s 602ms/step - loss: 0.2096 - f1score: 0.9342 - acc: 0.9343 - val_loss: 0.5800 - val_f1score: 0.8569 - val_acc: 0.8532 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.2014 - f1score: 0.9398 - acc: 0.9386\n",
      "Epoch 21: val_loss did not improve from 0.57998\n",
      "863/863 [==============================] - 516s 598ms/step - loss: 0.2014 - f1score: 0.9398 - acc: 0.9386 - val_loss: 0.7112 - val_f1score: 0.8344 - val_acc: 0.8292 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.1703 - f1score: 0.9456 - acc: 0.9453\n",
      "Epoch 22: val_loss did not improve from 0.57998\n",
      "863/863 [==============================] - 518s 600ms/step - loss: 0.1703 - f1score: 0.9456 - acc: 0.9453 - val_loss: 0.6176 - val_f1score: 0.8500 - val_acc: 0.8471 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.1810 - f1score: 0.9426 - acc: 0.9434\n",
      "Epoch 23: val_loss did not improve from 0.57998\n",
      "863/863 [==============================] - 516s 598ms/step - loss: 0.1810 - f1score: 0.9426 - acc: 0.9434 - val_loss: 0.6168 - val_f1score: 0.8560 - val_acc: 0.8503 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.1644 - f1score: 0.9488 - acc: 0.9492\n",
      "Epoch 24: val_loss did not improve from 0.57998\n",
      "863/863 [==============================] - 518s 601ms/step - loss: 0.1644 - f1score: 0.9488 - acc: 0.9492 - val_loss: 0.8462 - val_f1score: 0.8140 - val_acc: 0.8077 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.1756 - f1score: 0.9445 - acc: 0.9450\n",
      "Epoch 25: val_loss improved from 0.57998 to 0.54895, saving model to /data/data/05_DACON/Artist/data/fold2_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "863/863 [==============================] - 516s 598ms/step - loss: 0.1756 - f1score: 0.9445 - acc: 0.9450 - val_loss: 0.5489 - val_f1score: 0.8705 - val_acc: 0.8658 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.1603 - f1score: 0.9500 - acc: 0.9507\n",
      "Epoch 26: val_loss did not improve from 0.54895\n",
      "863/863 [==============================] - 520s 603ms/step - loss: 0.1603 - f1score: 0.9500 - acc: 0.9507 - val_loss: 0.6703 - val_f1score: 0.8447 - val_acc: 0.8401 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.1636 - f1score: 0.9491 - acc: 0.9484\n",
      "Epoch 27: val_loss did not improve from 0.54895\n",
      "863/863 [==============================] - 522s 605ms/step - loss: 0.1636 - f1score: 0.9491 - acc: 0.9484 - val_loss: 0.6730 - val_f1score: 0.8431 - val_acc: 0.8376 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.1564 - f1score: 0.9524 - acc: 0.9521\n",
      "Epoch 28: val_loss did not improve from 0.54895\n",
      "863/863 [==============================] - 515s 596ms/step - loss: 0.1564 - f1score: 0.9524 - acc: 0.9521 - val_loss: 0.7870 - val_f1score: 0.8277 - val_acc: 0.8232 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.1608 - f1score: 0.9490 - acc: 0.9490\n",
      "Epoch 29: val_loss did not improve from 0.54895\n",
      "863/863 [==============================] - 516s 598ms/step - loss: 0.1608 - f1score: 0.9490 - acc: 0.9490 - val_loss: 0.6243 - val_f1score: 0.8541 - val_acc: 0.8507 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.1483 - f1score: 0.9542 - acc: 0.9546\n",
      "Epoch 30: val_loss did not improve from 0.54895\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "863/863 [==============================] - 516s 598ms/step - loss: 0.1483 - f1score: 0.9542 - acc: 0.9546 - val_loss: 0.8897 - val_f1score: 0.8105 - val_acc: 0.8053 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0746 - f1score: 0.9753 - acc: 0.9761\n",
      "Epoch 31: val_loss improved from 0.54895 to 0.29549, saving model to /data/data/05_DACON/Artist/data/fold2_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "863/863 [==============================] - 515s 596ms/step - loss: 0.0746 - f1score: 0.9753 - acc: 0.9761 - val_loss: 0.2955 - val_f1score: 0.9267 - val_acc: 0.9253 - lr: 5.0000e-04\n",
      "Epoch 32/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0448 - f1score: 0.9849 - acc: 0.9858\n",
      "Epoch 32: val_loss did not improve from 0.29549\n",
      "863/863 [==============================] - 516s 597ms/step - loss: 0.0448 - f1score: 0.9849 - acc: 0.9858 - val_loss: 0.3131 - val_f1score: 0.9244 - val_acc: 0.9221 - lr: 5.0000e-04\n",
      "Epoch 33/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0533 - f1score: 0.9819 - acc: 0.9830\n",
      "Epoch 33: val_loss did not improve from 0.29549\n",
      "863/863 [==============================] - 518s 600ms/step - loss: 0.0533 - f1score: 0.9819 - acc: 0.9830 - val_loss: 0.3302 - val_f1score: 0.9230 - val_acc: 0.9195 - lr: 5.0000e-04\n",
      "Epoch 34/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0517 - f1score: 0.9829 - acc: 0.9837\n",
      "Epoch 34: val_loss did not improve from 0.29549\n",
      "863/863 [==============================] - 520s 602ms/step - loss: 0.0517 - f1score: 0.9829 - acc: 0.9837 - val_loss: 0.3143 - val_f1score: 0.9248 - val_acc: 0.9224 - lr: 5.0000e-04\n",
      "Epoch 35/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0554 - f1score: 0.9819 - acc: 0.9829\n",
      "Epoch 35: val_loss did not improve from 0.29549\n",
      "863/863 [==============================] - 516s 598ms/step - loss: 0.0554 - f1score: 0.9819 - acc: 0.9829 - val_loss: 0.3677 - val_f1score: 0.9139 - val_acc: 0.9110 - lr: 5.0000e-04\n",
      "Epoch 36/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0472 - f1score: 0.9841 - acc: 0.9853\n",
      "Epoch 36: val_loss did not improve from 0.29549\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "863/863 [==============================] - 519s 601ms/step - loss: 0.0472 - f1score: 0.9841 - acc: 0.9853 - val_loss: 0.4180 - val_f1score: 0.9060 - val_acc: 0.9041 - lr: 5.0000e-04\n",
      "Epoch 37/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0333 - f1score: 0.9884 - acc: 0.9895\n",
      "Epoch 37: val_loss improved from 0.29549 to 0.27265, saving model to /data/data/05_DACON/Artist/data/fold2_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "863/863 [==============================] - 521s 603ms/step - loss: 0.0333 - f1score: 0.9884 - acc: 0.9895 - val_loss: 0.2727 - val_f1score: 0.9371 - val_acc: 0.9350 - lr: 2.5000e-04\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "863/863 [==============================] - ETA: 0s - loss: 0.0199 - f1score: 0.9925 - acc: 0.9937\n",
      "Epoch 38: val_loss improved from 0.27265 to 0.26626, saving model to /data/data/05_DACON/Artist/data/fold2_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "863/863 [==============================] - 517s 599ms/step - loss: 0.0199 - f1score: 0.9925 - acc: 0.9937 - val_loss: 0.2663 - val_f1score: 0.9391 - val_acc: 0.9367 - lr: 2.5000e-04\n",
      "Epoch 39/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0196 - f1score: 0.9922 - acc: 0.9933\n",
      "Epoch 39: val_loss improved from 0.26626 to 0.25900, saving model to /data/data/05_DACON/Artist/data/fold2_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "863/863 [==============================] - 516s 598ms/step - loss: 0.0196 - f1score: 0.9922 - acc: 0.9933 - val_loss: 0.2590 - val_f1score: 0.9413 - val_acc: 0.9395 - lr: 2.5000e-04\n",
      "Epoch 40/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0224 - f1score: 0.9918 - acc: 0.9930\n",
      "Epoch 40: val_loss did not improve from 0.25900\n",
      "863/863 [==============================] - 515s 596ms/step - loss: 0.0224 - f1score: 0.9918 - acc: 0.9930 - val_loss: 0.2874 - val_f1score: 0.9368 - val_acc: 0.9342 - lr: 2.5000e-04\n",
      "Epoch 41/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0222 - f1score: 0.9920 - acc: 0.9930\n",
      "Epoch 41: val_loss did not improve from 0.25900\n",
      "863/863 [==============================] - 514s 596ms/step - loss: 0.0222 - f1score: 0.9920 - acc: 0.9930 - val_loss: 0.2769 - val_f1score: 0.9376 - val_acc: 0.9357 - lr: 2.5000e-04\n",
      "Epoch 42/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0191 - f1score: 0.9925 - acc: 0.9935\n",
      "Epoch 42: val_loss improved from 0.25900 to 0.25737, saving model to /data/data/05_DACON/Artist/data/fold2_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "863/863 [==============================] - 517s 599ms/step - loss: 0.0191 - f1score: 0.9925 - acc: 0.9935 - val_loss: 0.2574 - val_f1score: 0.9414 - val_acc: 0.9395 - lr: 2.5000e-04\n",
      "Epoch 43/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0185 - f1score: 0.9930 - acc: 0.9941\n",
      "Epoch 43: val_loss did not improve from 0.25737\n",
      "863/863 [==============================] - 513s 595ms/step - loss: 0.0185 - f1score: 0.9930 - acc: 0.9941 - val_loss: 0.2753 - val_f1score: 0.9387 - val_acc: 0.9365 - lr: 2.5000e-04\n",
      "Epoch 44/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0193 - f1score: 0.9928 - acc: 0.9941\n",
      "Epoch 44: val_loss did not improve from 0.25737\n",
      "863/863 [==============================] - 520s 603ms/step - loss: 0.0193 - f1score: 0.9928 - acc: 0.9941 - val_loss: 0.2641 - val_f1score: 0.9416 - val_acc: 0.9398 - lr: 2.5000e-04\n",
      "Epoch 45/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0187 - f1score: 0.9929 - acc: 0.9939\n",
      "Epoch 45: val_loss did not improve from 0.25737\n",
      "863/863 [==============================] - 523s 606ms/step - loss: 0.0187 - f1score: 0.9929 - acc: 0.9939 - val_loss: 0.2997 - val_f1score: 0.9375 - val_acc: 0.9358 - lr: 2.5000e-04\n",
      "Epoch 46/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0179 - f1score: 0.9934 - acc: 0.9944\n",
      "Epoch 46: val_loss did not improve from 0.25737\n",
      "863/863 [==============================] - 521s 603ms/step - loss: 0.0179 - f1score: 0.9934 - acc: 0.9944 - val_loss: 0.2695 - val_f1score: 0.9399 - val_acc: 0.9379 - lr: 2.5000e-04\n",
      "Epoch 47/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0162 - f1score: 0.9937 - acc: 0.9947\n",
      "Epoch 47: val_loss did not improve from 0.25737\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "863/863 [==============================] - 516s 597ms/step - loss: 0.0162 - f1score: 0.9937 - acc: 0.9947 - val_loss: 0.3197 - val_f1score: 0.9340 - val_acc: 0.9319 - lr: 2.5000e-04\n",
      "Epoch 48/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0140 - f1score: 0.9945 - acc: 0.9955\n",
      "Epoch 48: val_loss did not improve from 0.25737\n",
      "863/863 [==============================] - 516s 598ms/step - loss: 0.0140 - f1score: 0.9945 - acc: 0.9955 - val_loss: 0.2645 - val_f1score: 0.9464 - val_acc: 0.9448 - lr: 1.2500e-04\n",
      "Epoch 49/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0092 - f1score: 0.9959 - acc: 0.9971\n",
      "Epoch 49: val_loss improved from 0.25737 to 0.24780, saving model to /data/data/05_DACON/Artist/data/fold2_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "863/863 [==============================] - 520s 602ms/step - loss: 0.0092 - f1score: 0.9959 - acc: 0.9971 - val_loss: 0.2478 - val_f1score: 0.9448 - val_acc: 0.9432 - lr: 1.2500e-04\n",
      "Epoch 50/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0094 - f1score: 0.9956 - acc: 0.9967\n",
      "Epoch 50: val_loss improved from 0.24780 to 0.23390, saving model to /data/data/05_DACON/Artist/data/fold2_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "863/863 [==============================] - 516s 598ms/step - loss: 0.0094 - f1score: 0.9956 - acc: 0.9967 - val_loss: 0.2339 - val_f1score: 0.9481 - val_acc: 0.9457 - lr: 1.2500e-04\n",
      "Found 27585 validated image filenames belonging to 50 classes.\n",
      "Found 13792 validated image filenames belonging to 50 classes.\n",
      "Epoch 1/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 1.7310 - f1score: 0.4876 - acc: 0.5313\n",
      "Epoch 1: val_loss improved from inf to 1.81591, saving model to /data/data/05_DACON/Artist/data/fold3_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "863/863 [==============================] - 529s 604ms/step - loss: 1.7310 - f1score: 0.4876 - acc: 0.5313 - val_loss: 1.8159 - val_f1score: 0.5620 - val_acc: 0.5610 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 1.0607 - f1score: 0.6866 - acc: 0.6929\n",
      "Epoch 2: val_loss improved from 1.81591 to 1.08971, saving model to /data/data/05_DACON/Artist/data/fold3_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "863/863 [==============================] - 522s 604ms/step - loss: 1.0607 - f1score: 0.6866 - acc: 0.6929 - val_loss: 1.0897 - val_f1score: 0.7069 - val_acc: 0.7023 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.8266 - f1score: 0.7527 - acc: 0.7535\n",
      "Epoch 3: val_loss did not improve from 1.08971\n",
      "863/863 [==============================] - 522s 605ms/step - loss: 0.8266 - f1score: 0.7527 - acc: 0.7535 - val_loss: 1.1739 - val_f1score: 0.6933 - val_acc: 0.6852 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.6742 - f1score: 0.8003 - acc: 0.7999\n",
      "Epoch 4: val_loss improved from 1.08971 to 0.97908, saving model to /data/data/05_DACON/Artist/data/fold3_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "863/863 [==============================] - 523s 606ms/step - loss: 0.6742 - f1score: 0.8003 - acc: 0.7999 - val_loss: 0.9791 - val_f1score: 0.7502 - val_acc: 0.7454 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.5781 - f1score: 0.8243 - acc: 0.8245\n",
      "Epoch 5: val_loss improved from 0.97908 to 0.76308, saving model to /data/data/05_DACON/Artist/data/fold3_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "863/863 [==============================] - 519s 601ms/step - loss: 0.5781 - f1score: 0.8243 - acc: 0.8245 - val_loss: 0.7631 - val_f1score: 0.7921 - val_acc: 0.7862 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.5100 - f1score: 0.8441 - acc: 0.8432\n",
      "Epoch 6: val_loss did not improve from 0.76308\n",
      "863/863 [==============================] - 521s 603ms/step - loss: 0.5100 - f1score: 0.8441 - acc: 0.8432 - val_loss: 0.9389 - val_f1score: 0.7593 - val_acc: 0.7541 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.4424 - f1score: 0.8655 - acc: 0.8646\n",
      "Epoch 7: val_loss did not improve from 0.76308\n",
      "863/863 [==============================] - 520s 602ms/step - loss: 0.4424 - f1score: 0.8655 - acc: 0.8646 - val_loss: 1.5609 - val_f1score: 0.6772 - val_acc: 0.6731 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.4089 - f1score: 0.8749 - acc: 0.8736\n",
      "Epoch 8: val_loss did not improve from 0.76308\n",
      "863/863 [==============================] - 520s 602ms/step - loss: 0.4089 - f1score: 0.8749 - acc: 0.8736 - val_loss: 1.0576 - val_f1score: 0.7507 - val_acc: 0.7443 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.3708 - f1score: 0.8856 - acc: 0.8840\n",
      "Epoch 9: val_loss did not improve from 0.76308\n",
      "863/863 [==============================] - 520s 602ms/step - loss: 0.3708 - f1score: 0.8856 - acc: 0.8840 - val_loss: 0.7863 - val_f1score: 0.8065 - val_acc: 0.8009 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.3310 - f1score: 0.9014 - acc: 0.8993\n",
      "Epoch 10: val_loss improved from 0.76308 to 0.70061, saving model to /data/data/05_DACON/Artist/data/fold3_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "863/863 [==============================] - 521s 603ms/step - loss: 0.3310 - f1score: 0.9014 - acc: 0.8993 - val_loss: 0.7006 - val_f1score: 0.8270 - val_acc: 0.8223 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.3201 - f1score: 0.9001 - acc: 0.8994\n",
      "Epoch 11: val_loss improved from 0.70061 to 0.57039, saving model to /data/data/05_DACON/Artist/data/fold3_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "863/863 [==============================] - 517s 598ms/step - loss: 0.3201 - f1score: 0.9001 - acc: 0.8994 - val_loss: 0.5704 - val_f1score: 0.8509 - val_acc: 0.8475 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.2921 - f1score: 0.9109 - acc: 0.9101\n",
      "Epoch 12: val_loss did not improve from 0.57039\n",
      "863/863 [==============================] - 519s 601ms/step - loss: 0.2921 - f1score: 0.9109 - acc: 0.9101 - val_loss: 0.7652 - val_f1score: 0.8242 - val_acc: 0.8184 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.2891 - f1score: 0.9095 - acc: 0.9085\n",
      "Epoch 13: val_loss did not improve from 0.57039\n",
      "863/863 [==============================] - 515s 596ms/step - loss: 0.2891 - f1score: 0.9095 - acc: 0.9085 - val_loss: 0.6075 - val_f1score: 0.8438 - val_acc: 0.8395 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.2484 - f1score: 0.9221 - acc: 0.9221\n",
      "Epoch 14: val_loss did not improve from 0.57039\n",
      "863/863 [==============================] - 519s 601ms/step - loss: 0.2484 - f1score: 0.9221 - acc: 0.9221 - val_loss: 0.6286 - val_f1score: 0.8404 - val_acc: 0.8362 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.2553 - f1score: 0.9215 - acc: 0.9206\n",
      "Epoch 15: val_loss did not improve from 0.57039\n",
      "863/863 [==============================] - 521s 603ms/step - loss: 0.2553 - f1score: 0.9215 - acc: 0.9206 - val_loss: 0.6519 - val_f1score: 0.8445 - val_acc: 0.8390 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.2355 - f1score: 0.9264 - acc: 0.9270\n",
      "Epoch 16: val_loss did not improve from 0.57039\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "863/863 [==============================] - 517s 599ms/step - loss: 0.2355 - f1score: 0.9264 - acc: 0.9270 - val_loss: 1.1535 - val_f1score: 0.7955 - val_acc: 0.7902 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.1122 - f1score: 0.9644 - acc: 0.9649\n",
      "Epoch 17: val_loss improved from 0.57039 to 0.32413, saving model to /data/data/05_DACON/Artist/data/fold3_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "863/863 [==============================] - 518s 600ms/step - loss: 0.1122 - f1score: 0.9644 - acc: 0.9649 - val_loss: 0.3241 - val_f1score: 0.9157 - val_acc: 0.9124 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0838 - f1score: 0.9725 - acc: 0.9732\n",
      "Epoch 18: val_loss did not improve from 0.32413\n",
      "863/863 [==============================] - 521s 603ms/step - loss: 0.0838 - f1score: 0.9725 - acc: 0.9732 - val_loss: 0.3660 - val_f1score: 0.9090 - val_acc: 0.9054 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0870 - f1score: 0.9713 - acc: 0.9717\n",
      "Epoch 19: val_loss did not improve from 0.32413\n",
      "863/863 [==============================] - 519s 601ms/step - loss: 0.0870 - f1score: 0.9713 - acc: 0.9717 - val_loss: 0.4430 - val_f1score: 0.8928 - val_acc: 0.8884 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0875 - f1score: 0.9721 - acc: 0.9728\n",
      "Epoch 20: val_loss did not improve from 0.32413\n",
      "863/863 [==============================] - 517s 599ms/step - loss: 0.0875 - f1score: 0.9721 - acc: 0.9728 - val_loss: 0.4017 - val_f1score: 0.9094 - val_acc: 0.9056 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0806 - f1score: 0.9728 - acc: 0.9732\n",
      "Epoch 21: val_loss did not improve from 0.32413\n",
      "863/863 [==============================] - 523s 606ms/step - loss: 0.0806 - f1score: 0.9728 - acc: 0.9732 - val_loss: 0.3908 - val_f1score: 0.9063 - val_acc: 0.9034 - lr: 5.0000e-04\n",
      "Epoch 22/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0748 - f1score: 0.9753 - acc: 0.9759\n",
      "Epoch 22: val_loss did not improve from 0.32413\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "863/863 [==============================] - 524s 607ms/step - loss: 0.0748 - f1score: 0.9753 - acc: 0.9759 - val_loss: 0.3675 - val_f1score: 0.9085 - val_acc: 0.9049 - lr: 5.0000e-04\n",
      "Epoch 23/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0524 - f1score: 0.9822 - acc: 0.9830\n",
      "Epoch 23: val_loss improved from 0.32413 to 0.26257, saving model to /data/data/05_DACON/Artist/data/fold3_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "863/863 [==============================] - 515s 596ms/step - loss: 0.0524 - f1score: 0.9822 - acc: 0.9830 - val_loss: 0.2626 - val_f1score: 0.9359 - val_acc: 0.9338 - lr: 2.5000e-04\n",
      "Epoch 24/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0329 - f1score: 0.9888 - acc: 0.9897\n",
      "Epoch 24: val_loss did not improve from 0.26257\n",
      "863/863 [==============================] - 520s 602ms/step - loss: 0.0329 - f1score: 0.9888 - acc: 0.9897 - val_loss: 0.2712 - val_f1score: 0.9337 - val_acc: 0.9324 - lr: 2.5000e-04\n",
      "Epoch 25/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0316 - f1score: 0.9888 - acc: 0.9901\n",
      "Epoch 25: val_loss did not improve from 0.26257\n",
      "863/863 [==============================] - 516s 598ms/step - loss: 0.0316 - f1score: 0.9888 - acc: 0.9901 - val_loss: 0.2974 - val_f1score: 0.9320 - val_acc: 0.9295 - lr: 2.5000e-04\n",
      "Epoch 26/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0295 - f1score: 0.9896 - acc: 0.9906\n",
      "Epoch 26: val_loss did not improve from 0.26257\n",
      "863/863 [==============================] - 523s 605ms/step - loss: 0.0295 - f1score: 0.9896 - acc: 0.9906 - val_loss: 0.2907 - val_f1score: 0.9351 - val_acc: 0.9331 - lr: 2.5000e-04\n",
      "Epoch 27/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0327 - f1score: 0.9889 - acc: 0.9896\n",
      "Epoch 27: val_loss did not improve from 0.26257\n",
      "863/863 [==============================] - 514s 596ms/step - loss: 0.0327 - f1score: 0.9889 - acc: 0.9896 - val_loss: 0.2843 - val_f1score: 0.9341 - val_acc: 0.9329 - lr: 2.5000e-04\n",
      "Epoch 28/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0310 - f1score: 0.9887 - acc: 0.9895\n",
      "Epoch 28: val_loss did not improve from 0.26257\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "863/863 [==============================] - 524s 607ms/step - loss: 0.0310 - f1score: 0.9887 - acc: 0.9895 - val_loss: 0.2855 - val_f1score: 0.9372 - val_acc: 0.9357 - lr: 2.5000e-04\n",
      "Epoch 29/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0209 - f1score: 0.9924 - acc: 0.9937\n",
      "Epoch 29: val_loss improved from 0.26257 to 0.25579, saving model to /data/data/05_DACON/Artist/data/fold3_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "863/863 [==============================] - 525s 609ms/step - loss: 0.0209 - f1score: 0.9924 - acc: 0.9937 - val_loss: 0.2558 - val_f1score: 0.9436 - val_acc: 0.9423 - lr: 1.2500e-04\n",
      "Epoch 30/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0177 - f1score: 0.9930 - acc: 0.9941\n",
      "Epoch 30: val_loss did not improve from 0.25579\n",
      "863/863 [==============================] - 520s 603ms/step - loss: 0.0177 - f1score: 0.9930 - acc: 0.9941 - val_loss: 0.2779 - val_f1score: 0.9407 - val_acc: 0.9394 - lr: 1.2500e-04\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "863/863 [==============================] - ETA: 0s - loss: 0.0149 - f1score: 0.9942 - acc: 0.9953\n",
      "Epoch 31: val_loss improved from 0.25579 to 0.22892, saving model to /data/data/05_DACON/Artist/data/fold3_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "863/863 [==============================] - 523s 606ms/step - loss: 0.0149 - f1score: 0.9942 - acc: 0.9953 - val_loss: 0.2289 - val_f1score: 0.9496 - val_acc: 0.9480 - lr: 1.2500e-04\n",
      "Epoch 32/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0170 - f1score: 0.9930 - acc: 0.9941\n",
      "Epoch 32: val_loss did not improve from 0.22892\n",
      "863/863 [==============================] - 524s 607ms/step - loss: 0.0170 - f1score: 0.9930 - acc: 0.9941 - val_loss: 0.2686 - val_f1score: 0.9426 - val_acc: 0.9416 - lr: 1.2500e-04\n",
      "Epoch 33/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0136 - f1score: 0.9949 - acc: 0.9959\n",
      "Epoch 33: val_loss did not improve from 0.22892\n",
      "863/863 [==============================] - 520s 602ms/step - loss: 0.0136 - f1score: 0.9949 - acc: 0.9959 - val_loss: 0.2388 - val_f1score: 0.9465 - val_acc: 0.9443 - lr: 1.2500e-04\n",
      "Epoch 34/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0164 - f1score: 0.9938 - acc: 0.9949\n",
      "Epoch 34: val_loss did not improve from 0.22892\n",
      "863/863 [==============================] - 520s 602ms/step - loss: 0.0164 - f1score: 0.9938 - acc: 0.9949 - val_loss: 0.2439 - val_f1score: 0.9465 - val_acc: 0.9448 - lr: 1.2500e-04\n",
      "Epoch 35/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0131 - f1score: 0.9949 - acc: 0.9959\n",
      "Epoch 35: val_loss did not improve from 0.22892\n",
      "863/863 [==============================] - 524s 606ms/step - loss: 0.0131 - f1score: 0.9949 - acc: 0.9959 - val_loss: 0.2407 - val_f1score: 0.9458 - val_acc: 0.9441 - lr: 1.2500e-04\n",
      "Epoch 36/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0150 - f1score: 0.9938 - acc: 0.9947\n",
      "Epoch 36: val_loss did not improve from 0.22892\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "863/863 [==============================] - 519s 601ms/step - loss: 0.0150 - f1score: 0.9938 - acc: 0.9947 - val_loss: 0.2483 - val_f1score: 0.9468 - val_acc: 0.9453 - lr: 1.2500e-04\n",
      "Epoch 37/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0108 - f1score: 0.9956 - acc: 0.9967\n",
      "Epoch 37: val_loss improved from 0.22892 to 0.22847, saving model to /data/data/05_DACON/Artist/data/fold3_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "863/863 [==============================] - 522s 605ms/step - loss: 0.0108 - f1score: 0.9956 - acc: 0.9967 - val_loss: 0.2285 - val_f1score: 0.9518 - val_acc: 0.9507 - lr: 6.2500e-05\n",
      "Epoch 38/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0093 - f1score: 0.9960 - acc: 0.9972\n",
      "Epoch 38: val_loss improved from 0.22847 to 0.22204, saving model to /data/data/05_DACON/Artist/data/fold3_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "863/863 [==============================] - 520s 603ms/step - loss: 0.0093 - f1score: 0.9960 - acc: 0.9972 - val_loss: 0.2220 - val_f1score: 0.9502 - val_acc: 0.9498 - lr: 6.2500e-05\n",
      "Epoch 39/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0085 - f1score: 0.9960 - acc: 0.9972\n",
      "Epoch 39: val_loss did not improve from 0.22204\n",
      "863/863 [==============================] - 518s 600ms/step - loss: 0.0085 - f1score: 0.9960 - acc: 0.9972 - val_loss: 0.2231 - val_f1score: 0.9511 - val_acc: 0.9496 - lr: 6.2500e-05\n",
      "Epoch 40/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0083 - f1score: 0.9965 - acc: 0.9977\n",
      "Epoch 40: val_loss improved from 0.22204 to 0.22112, saving model to /data/data/05_DACON/Artist/data/fold3_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "863/863 [==============================] - 524s 607ms/step - loss: 0.0083 - f1score: 0.9965 - acc: 0.9977 - val_loss: 0.2211 - val_f1score: 0.9506 - val_acc: 0.9499 - lr: 6.2500e-05\n",
      "Epoch 41/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0089 - f1score: 0.9962 - acc: 0.9973\n",
      "Epoch 41: val_loss did not improve from 0.22112\n",
      "863/863 [==============================] - 523s 605ms/step - loss: 0.0089 - f1score: 0.9962 - acc: 0.9973 - val_loss: 0.2254 - val_f1score: 0.9516 - val_acc: 0.9506 - lr: 6.2500e-05\n",
      "Epoch 42/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0076 - f1score: 0.9965 - acc: 0.9976\n",
      "Epoch 42: val_loss did not improve from 0.22112\n",
      "863/863 [==============================] - 524s 607ms/step - loss: 0.0076 - f1score: 0.9965 - acc: 0.9976 - val_loss: 0.2305 - val_f1score: 0.9491 - val_acc: 0.9472 - lr: 6.2500e-05\n",
      "Epoch 43/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0070 - f1score: 0.9966 - acc: 0.9978\n",
      "Epoch 43: val_loss did not improve from 0.22112\n",
      "863/863 [==============================] - 520s 603ms/step - loss: 0.0070 - f1score: 0.9966 - acc: 0.9978 - val_loss: 0.2283 - val_f1score: 0.9514 - val_acc: 0.9498 - lr: 6.2500e-05\n",
      "Epoch 44/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0066 - f1score: 0.9971 - acc: 0.9981\n",
      "Epoch 44: val_loss did not improve from 0.22112\n",
      "863/863 [==============================] - 522s 604ms/step - loss: 0.0066 - f1score: 0.9971 - acc: 0.9981 - val_loss: 0.2298 - val_f1score: 0.9509 - val_acc: 0.9494 - lr: 6.2500e-05\n",
      "Epoch 45/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0084 - f1score: 0.9963 - acc: 0.9975\n",
      "Epoch 45: val_loss did not improve from 0.22112\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "863/863 [==============================] - 518s 600ms/step - loss: 0.0084 - f1score: 0.9963 - acc: 0.9975 - val_loss: 0.2299 - val_f1score: 0.9517 - val_acc: 0.9505 - lr: 6.2500e-05\n",
      "Epoch 46/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0069 - f1score: 0.9968 - acc: 0.9979\n",
      "Epoch 46: val_loss did not improve from 0.22112\n",
      "863/863 [==============================] - 516s 598ms/step - loss: 0.0069 - f1score: 0.9968 - acc: 0.9979 - val_loss: 0.2277 - val_f1score: 0.9533 - val_acc: 0.9513 - lr: 3.1250e-05\n",
      "Epoch 47/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0070 - f1score: 0.9968 - acc: 0.9979\n",
      "Epoch 47: val_loss did not improve from 0.22112\n",
      "863/863 [==============================] - 522s 605ms/step - loss: 0.0070 - f1score: 0.9968 - acc: 0.9979 - val_loss: 0.2272 - val_f1score: 0.9518 - val_acc: 0.9512 - lr: 3.1250e-05\n",
      "Epoch 48/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0050 - f1score: 0.9971 - acc: 0.9984\n",
      "Epoch 48: val_loss did not improve from 0.22112\n",
      "863/863 [==============================] - 520s 602ms/step - loss: 0.0050 - f1score: 0.9971 - acc: 0.9984 - val_loss: 0.2280 - val_f1score: 0.9518 - val_acc: 0.9503 - lr: 3.1250e-05\n",
      "Epoch 49/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0055 - f1score: 0.9972 - acc: 0.9982\n",
      "Epoch 49: val_loss did not improve from 0.22112\n",
      "863/863 [==============================] - 522s 605ms/step - loss: 0.0055 - f1score: 0.9972 - acc: 0.9982 - val_loss: 0.2217 - val_f1score: 0.9539 - val_acc: 0.9524 - lr: 3.1250e-05\n",
      "Epoch 50/50\n",
      "863/863 [==============================] - ETA: 0s - loss: 0.0048 - f1score: 0.9973 - acc: 0.9984\n",
      "Epoch 50: val_loss improved from 0.22112 to 0.21906, saving model to /data/data/05_DACON/Artist/data/fold3_EfficientNetB3_raw_2_4_best_221107.h5\n",
      "863/863 [==============================] - 526s 609ms/step - loss: 0.0048 - f1score: 0.9973 - acc: 0.9984 - val_loss: 0.2191 - val_f1score: 0.9547 - val_acc: 0.9537 - lr: 3.1250e-05\n"
     ]
    }
   ],
   "source": [
    "model = EfficientNetB3_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a712e867",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T04:27:23.652017Z",
     "start_time": "2022-11-08T04:27:23.288227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 300, 300, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " rescaling_2 (Rescaling)        (None, 300, 300, 3)  0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " normalization_2 (Normalization  (None, 300, 300, 3)  7          ['rescaling_2[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_2 (TFOpLambda)  (None, 300, 300, 3)  0          ['normalization_2[0][0]']        \n",
      "                                                                                                  \n",
      " stem_conv_pad (ZeroPadding2D)  (None, 301, 301, 3)  0           ['tf.math.truediv_2[0][0]']      \n",
      "                                                                                                  \n",
      " stem_conv (Conv2D)             (None, 150, 150, 40  1080        ['stem_conv_pad[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " stem_bn (BatchNormalization)   (None, 150, 150, 40  160         ['stem_conv[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " stem_activation (Activation)   (None, 150, 150, 40  0           ['stem_bn[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1a_dwconv (DepthwiseConv2  (None, 150, 150, 40  360        ['stem_activation[0][0]']        \n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " block1a_bn (BatchNormalization  (None, 150, 150, 40  160        ['block1a_dwconv[0][0]']         \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block1a_activation (Activation  (None, 150, 150, 40  0          ['block1a_bn[0][0]']             \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block1a_se_squeeze (GlobalAver  (None, 40)          0           ['block1a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block1a_se_reshape (Reshape)   (None, 1, 1, 40)     0           ['block1a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block1a_se_reduce (Conv2D)     (None, 1, 1, 10)     410         ['block1a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block1a_se_expand (Conv2D)     (None, 1, 1, 40)     440         ['block1a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block1a_se_excite (Multiply)   (None, 150, 150, 40  0           ['block1a_activation[0][0]',     \n",
      "                                )                                 'block1a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block1a_project_conv (Conv2D)  (None, 150, 150, 24  960         ['block1a_se_excite[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1a_project_bn (BatchNorma  (None, 150, 150, 24  96         ['block1a_project_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " block1b_dwconv (DepthwiseConv2  (None, 150, 150, 24  216        ['block1a_project_bn[0][0]']     \n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " block1b_bn (BatchNormalization  (None, 150, 150, 24  96         ['block1b_dwconv[0][0]']         \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block1b_activation (Activation  (None, 150, 150, 24  0          ['block1b_bn[0][0]']             \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block1b_se_squeeze (GlobalAver  (None, 24)          0           ['block1b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block1b_se_reshape (Reshape)   (None, 1, 1, 24)     0           ['block1b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block1b_se_reduce (Conv2D)     (None, 1, 1, 6)      150         ['block1b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block1b_se_expand (Conv2D)     (None, 1, 1, 24)     168         ['block1b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block1b_se_excite (Multiply)   (None, 150, 150, 24  0           ['block1b_activation[0][0]',     \n",
      "                                )                                 'block1b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block1b_project_conv (Conv2D)  (None, 150, 150, 24  576         ['block1b_se_excite[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1b_project_bn (BatchNorma  (None, 150, 150, 24  96         ['block1b_project_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " block1b_drop (Dropout)         (None, 150, 150, 24  0           ['block1b_project_bn[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1b_add (Add)              (None, 150, 150, 24  0           ['block1b_drop[0][0]',           \n",
      "                                )                                 'block1a_project_bn[0][0]']     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " block2a_expand_conv (Conv2D)   (None, 150, 150, 14  3456        ['block1b_add[0][0]']            \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " block2a_expand_bn (BatchNormal  (None, 150, 150, 14  576        ['block2a_expand_conv[0][0]']    \n",
      " ization)                       4)                                                                \n",
      "                                                                                                  \n",
      " block2a_expand_activation (Act  (None, 150, 150, 14  0          ['block2a_expand_bn[0][0]']      \n",
      " ivation)                       4)                                                                \n",
      "                                                                                                  \n",
      " block2a_dwconv_pad (ZeroPaddin  (None, 151, 151, 14  0          ['block2a_expand_activation[0][0]\n",
      " g2D)                           4)                               ']                               \n",
      "                                                                                                  \n",
      " block2a_dwconv (DepthwiseConv2  (None, 75, 75, 144)  1296       ['block2a_dwconv_pad[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block2a_bn (BatchNormalization  (None, 75, 75, 144)  576        ['block2a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2a_activation (Activation  (None, 75, 75, 144)  0          ['block2a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2a_se_squeeze (GlobalAver  (None, 144)         0           ['block2a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block2a_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block2a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block2a_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block2a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block2a_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block2a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block2a_se_excite (Multiply)   (None, 75, 75, 144)  0           ['block2a_activation[0][0]',     \n",
      "                                                                  'block2a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block2a_project_conv (Conv2D)  (None, 75, 75, 32)   4608        ['block2a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block2a_project_bn (BatchNorma  (None, 75, 75, 32)  128         ['block2a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block2b_expand_conv (Conv2D)   (None, 75, 75, 192)  6144        ['block2a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_expand_bn (BatchNormal  (None, 75, 75, 192)  768        ['block2b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block2b_expand_activation (Act  (None, 75, 75, 192)  0          ['block2b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block2b_dwconv (DepthwiseConv2  (None, 75, 75, 192)  1728       ['block2b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block2b_bn (BatchNormalization  (None, 75, 75, 192)  768        ['block2b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2b_activation (Activation  (None, 75, 75, 192)  0          ['block2b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2b_se_squeeze (GlobalAver  (None, 192)         0           ['block2b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block2b_se_reshape (Reshape)   (None, 1, 1, 192)    0           ['block2b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_se_reduce (Conv2D)     (None, 1, 1, 8)      1544        ['block2b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_se_expand (Conv2D)     (None, 1, 1, 192)    1728        ['block2b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block2b_se_excite (Multiply)   (None, 75, 75, 192)  0           ['block2b_activation[0][0]',     \n",
      "                                                                  'block2b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block2b_project_conv (Conv2D)  (None, 75, 75, 32)   6144        ['block2b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block2b_project_bn (BatchNorma  (None, 75, 75, 32)  128         ['block2b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block2b_drop (Dropout)         (None, 75, 75, 32)   0           ['block2b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_add (Add)              (None, 75, 75, 32)   0           ['block2b_drop[0][0]',           \n",
      "                                                                  'block2a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block2c_expand_conv (Conv2D)   (None, 75, 75, 192)  6144        ['block2b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block2c_expand_bn (BatchNormal  (None, 75, 75, 192)  768        ['block2c_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block2c_expand_activation (Act  (None, 75, 75, 192)  0          ['block2c_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block2c_dwconv (DepthwiseConv2  (None, 75, 75, 192)  1728       ['block2c_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block2c_bn (BatchNormalization  (None, 75, 75, 192)  768        ['block2c_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2c_activation (Activation  (None, 75, 75, 192)  0          ['block2c_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2c_se_squeeze (GlobalAver  (None, 192)         0           ['block2c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block2c_se_reshape (Reshape)   (None, 1, 1, 192)    0           ['block2c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block2c_se_reduce (Conv2D)     (None, 1, 1, 8)      1544        ['block2c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block2c_se_expand (Conv2D)     (None, 1, 1, 192)    1728        ['block2c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block2c_se_excite (Multiply)   (None, 75, 75, 192)  0           ['block2c_activation[0][0]',     \n",
      "                                                                  'block2c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block2c_project_conv (Conv2D)  (None, 75, 75, 32)   6144        ['block2c_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block2c_project_bn (BatchNorma  (None, 75, 75, 32)  128         ['block2c_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block2c_drop (Dropout)         (None, 75, 75, 32)   0           ['block2c_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block2c_add (Add)              (None, 75, 75, 32)   0           ['block2c_drop[0][0]',           \n",
      "                                                                  'block2b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block3a_expand_conv (Conv2D)   (None, 75, 75, 192)  6144        ['block2c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block3a_expand_bn (BatchNormal  (None, 75, 75, 192)  768        ['block3a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block3a_expand_activation (Act  (None, 75, 75, 192)  0          ['block3a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block3a_dwconv_pad (ZeroPaddin  (None, 79, 79, 192)  0          ['block3a_expand_activation[0][0]\n",
      " g2D)                                                            ']                               \n",
      "                                                                                                  \n",
      " block3a_dwconv (DepthwiseConv2  (None, 38, 38, 192)  4800       ['block3a_dwconv_pad[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block3a_bn (BatchNormalization  (None, 38, 38, 192)  768        ['block3a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3a_activation (Activation  (None, 38, 38, 192)  0          ['block3a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3a_se_squeeze (GlobalAver  (None, 192)         0           ['block3a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block3a_se_reshape (Reshape)   (None, 1, 1, 192)    0           ['block3a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block3a_se_reduce (Conv2D)     (None, 1, 1, 8)      1544        ['block3a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block3a_se_expand (Conv2D)     (None, 1, 1, 192)    1728        ['block3a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block3a_se_excite (Multiply)   (None, 38, 38, 192)  0           ['block3a_activation[0][0]',     \n",
      "                                                                  'block3a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block3a_project_conv (Conv2D)  (None, 38, 38, 48)   9216        ['block3a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block3a_project_bn (BatchNorma  (None, 38, 38, 48)  192         ['block3a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block3b_expand_conv (Conv2D)   (None, 38, 38, 288)  13824       ['block3a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_expand_bn (BatchNormal  (None, 38, 38, 288)  1152       ['block3b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block3b_expand_activation (Act  (None, 38, 38, 288)  0          ['block3b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block3b_dwconv (DepthwiseConv2  (None, 38, 38, 288)  7200       ['block3b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block3b_bn (BatchNormalization  (None, 38, 38, 288)  1152       ['block3b_dwconv[0][0]']         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3b_activation (Activation  (None, 38, 38, 288)  0          ['block3b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3b_se_squeeze (GlobalAver  (None, 288)         0           ['block3b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block3b_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block3b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block3b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block3b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block3b_se_excite (Multiply)   (None, 38, 38, 288)  0           ['block3b_activation[0][0]',     \n",
      "                                                                  'block3b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block3b_project_conv (Conv2D)  (None, 38, 38, 48)   13824       ['block3b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block3b_project_bn (BatchNorma  (None, 38, 38, 48)  192         ['block3b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block3b_drop (Dropout)         (None, 38, 38, 48)   0           ['block3b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_add (Add)              (None, 38, 38, 48)   0           ['block3b_drop[0][0]',           \n",
      "                                                                  'block3a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3c_expand_conv (Conv2D)   (None, 38, 38, 288)  13824       ['block3b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block3c_expand_bn (BatchNormal  (None, 38, 38, 288)  1152       ['block3c_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block3c_expand_activation (Act  (None, 38, 38, 288)  0          ['block3c_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block3c_dwconv (DepthwiseConv2  (None, 38, 38, 288)  7200       ['block3c_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block3c_bn (BatchNormalization  (None, 38, 38, 288)  1152       ['block3c_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3c_activation (Activation  (None, 38, 38, 288)  0          ['block3c_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3c_se_squeeze (GlobalAver  (None, 288)         0           ['block3c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block3c_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block3c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block3c_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block3c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block3c_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block3c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block3c_se_excite (Multiply)   (None, 38, 38, 288)  0           ['block3c_activation[0][0]',     \n",
      "                                                                  'block3c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block3c_project_conv (Conv2D)  (None, 38, 38, 48)   13824       ['block3c_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block3c_project_bn (BatchNorma  (None, 38, 38, 48)  192         ['block3c_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block3c_drop (Dropout)         (None, 38, 38, 48)   0           ['block3c_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3c_add (Add)              (None, 38, 38, 48)   0           ['block3c_drop[0][0]',           \n",
      "                                                                  'block3b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4a_expand_conv (Conv2D)   (None, 38, 38, 288)  13824       ['block3c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4a_expand_bn (BatchNormal  (None, 38, 38, 288)  1152       ['block4a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4a_expand_activation (Act  (None, 38, 38, 288)  0          ['block4a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4a_dwconv_pad (ZeroPaddin  (None, 39, 39, 288)  0          ['block4a_expand_activation[0][0]\n",
      " g2D)                                                            ']                               \n",
      "                                                                                                  \n",
      " block4a_dwconv (DepthwiseConv2  (None, 19, 19, 288)  2592       ['block4a_dwconv_pad[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block4a_bn (BatchNormalization  (None, 19, 19, 288)  1152       ['block4a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block4a_activation (Activation  (None, 19, 19, 288)  0          ['block4a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4a_se_squeeze (GlobalAver  (None, 288)         0           ['block4a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4a_se_reshape (Reshape)   (None, 1, 1, 288)    0           ['block4a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4a_se_reduce (Conv2D)     (None, 1, 1, 12)     3468        ['block4a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4a_se_expand (Conv2D)     (None, 1, 1, 288)    3744        ['block4a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4a_se_excite (Multiply)   (None, 19, 19, 288)  0           ['block4a_activation[0][0]',     \n",
      "                                                                  'block4a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4a_project_conv (Conv2D)  (None, 19, 19, 96)   27648       ['block4a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4a_project_bn (BatchNorma  (None, 19, 19, 96)  384         ['block4a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4b_expand_conv (Conv2D)   (None, 19, 19, 576)  55296       ['block4a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_expand_bn (BatchNormal  (None, 19, 19, 576)  2304       ['block4b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4b_expand_activation (Act  (None, 19, 19, 576)  0          ['block4b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4b_dwconv (DepthwiseConv2  (None, 19, 19, 576)  5184       ['block4b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block4b_bn (BatchNormalization  (None, 19, 19, 576)  2304       ['block4b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4b_activation (Activation  (None, 19, 19, 576)  0          ['block4b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4b_se_squeeze (GlobalAver  (None, 576)         0           ['block4b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4b_se_reshape (Reshape)   (None, 1, 1, 576)    0           ['block4b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_se_reduce (Conv2D)     (None, 1, 1, 24)     13848       ['block4b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_se_expand (Conv2D)     (None, 1, 1, 576)    14400       ['block4b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4b_se_excite (Multiply)   (None, 19, 19, 576)  0           ['block4b_activation[0][0]',     \n",
      "                                                                  'block4b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4b_project_conv (Conv2D)  (None, 19, 19, 96)   55296       ['block4b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4b_project_bn (BatchNorma  (None, 19, 19, 96)  384         ['block4b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4b_drop (Dropout)         (None, 19, 19, 96)   0           ['block4b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_add (Add)              (None, 19, 19, 96)   0           ['block4b_drop[0][0]',           \n",
      "                                                                  'block4a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_expand_conv (Conv2D)   (None, 19, 19, 576)  55296       ['block4b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4c_expand_bn (BatchNormal  (None, 19, 19, 576)  2304       ['block4c_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4c_expand_activation (Act  (None, 19, 19, 576)  0          ['block4c_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4c_dwconv (DepthwiseConv2  (None, 19, 19, 576)  5184       ['block4c_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block4c_bn (BatchNormalization  (None, 19, 19, 576)  2304       ['block4c_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4c_activation (Activation  (None, 19, 19, 576)  0          ['block4c_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4c_se_squeeze (GlobalAver  (None, 576)         0           ['block4c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4c_se_reshape (Reshape)   (None, 1, 1, 576)    0           ['block4c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_se_reduce (Conv2D)     (None, 1, 1, 24)     13848       ['block4c_se_reshape[0][0]']     \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block4c_se_expand (Conv2D)     (None, 1, 1, 576)    14400       ['block4c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4c_se_excite (Multiply)   (None, 19, 19, 576)  0           ['block4c_activation[0][0]',     \n",
      "                                                                  'block4c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4c_project_conv (Conv2D)  (None, 19, 19, 96)   55296       ['block4c_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4c_project_bn (BatchNorma  (None, 19, 19, 96)  384         ['block4c_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4c_drop (Dropout)         (None, 19, 19, 96)   0           ['block4c_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_add (Add)              (None, 19, 19, 96)   0           ['block4c_drop[0][0]',           \n",
      "                                                                  'block4b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4d_expand_conv (Conv2D)   (None, 19, 19, 576)  55296       ['block4c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4d_expand_bn (BatchNormal  (None, 19, 19, 576)  2304       ['block4d_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4d_expand_activation (Act  (None, 19, 19, 576)  0          ['block4d_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4d_dwconv (DepthwiseConv2  (None, 19, 19, 576)  5184       ['block4d_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block4d_bn (BatchNormalization  (None, 19, 19, 576)  2304       ['block4d_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4d_activation (Activation  (None, 19, 19, 576)  0          ['block4d_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4d_se_squeeze (GlobalAver  (None, 576)         0           ['block4d_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4d_se_reshape (Reshape)   (None, 1, 1, 576)    0           ['block4d_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4d_se_reduce (Conv2D)     (None, 1, 1, 24)     13848       ['block4d_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4d_se_expand (Conv2D)     (None, 1, 1, 576)    14400       ['block4d_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4d_se_excite (Multiply)   (None, 19, 19, 576)  0           ['block4d_activation[0][0]',     \n",
      "                                                                  'block4d_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4d_project_conv (Conv2D)  (None, 19, 19, 96)   55296       ['block4d_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4d_project_bn (BatchNorma  (None, 19, 19, 96)  384         ['block4d_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4d_drop (Dropout)         (None, 19, 19, 96)   0           ['block4d_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4d_add (Add)              (None, 19, 19, 96)   0           ['block4d_drop[0][0]',           \n",
      "                                                                  'block4c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4e_expand_conv (Conv2D)   (None, 19, 19, 576)  55296       ['block4d_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4e_expand_bn (BatchNormal  (None, 19, 19, 576)  2304       ['block4e_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4e_expand_activation (Act  (None, 19, 19, 576)  0          ['block4e_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4e_dwconv (DepthwiseConv2  (None, 19, 19, 576)  5184       ['block4e_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block4e_bn (BatchNormalization  (None, 19, 19, 576)  2304       ['block4e_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4e_activation (Activation  (None, 19, 19, 576)  0          ['block4e_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4e_se_squeeze (GlobalAver  (None, 576)         0           ['block4e_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4e_se_reshape (Reshape)   (None, 1, 1, 576)    0           ['block4e_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4e_se_reduce (Conv2D)     (None, 1, 1, 24)     13848       ['block4e_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4e_se_expand (Conv2D)     (None, 1, 1, 576)    14400       ['block4e_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4e_se_excite (Multiply)   (None, 19, 19, 576)  0           ['block4e_activation[0][0]',     \n",
      "                                                                  'block4e_se_expand[0][0]']      \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block4e_project_conv (Conv2D)  (None, 19, 19, 96)   55296       ['block4e_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4e_project_bn (BatchNorma  (None, 19, 19, 96)  384         ['block4e_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4e_drop (Dropout)         (None, 19, 19, 96)   0           ['block4e_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4e_add (Add)              (None, 19, 19, 96)   0           ['block4e_drop[0][0]',           \n",
      "                                                                  'block4d_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5a_expand_conv (Conv2D)   (None, 19, 19, 576)  55296       ['block4e_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5a_expand_bn (BatchNormal  (None, 19, 19, 576)  2304       ['block5a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block5a_expand_activation (Act  (None, 19, 19, 576)  0          ['block5a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block5a_dwconv (DepthwiseConv2  (None, 19, 19, 576)  14400      ['block5a_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block5a_bn (BatchNormalization  (None, 19, 19, 576)  2304       ['block5a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5a_activation (Activation  (None, 19, 19, 576)  0          ['block5a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5a_se_squeeze (GlobalAver  (None, 576)         0           ['block5a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5a_se_reshape (Reshape)   (None, 1, 1, 576)    0           ['block5a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5a_se_reduce (Conv2D)     (None, 1, 1, 24)     13848       ['block5a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5a_se_expand (Conv2D)     (None, 1, 1, 576)    14400       ['block5a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5a_se_excite (Multiply)   (None, 19, 19, 576)  0           ['block5a_activation[0][0]',     \n",
      "                                                                  'block5a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5a_project_conv (Conv2D)  (None, 19, 19, 136)  78336       ['block5a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5a_project_bn (BatchNorma  (None, 19, 19, 136)  544        ['block5a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5b_expand_conv (Conv2D)   (None, 19, 19, 816)  110976      ['block5a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_expand_bn (BatchNormal  (None, 19, 19, 816)  3264       ['block5b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block5b_expand_activation (Act  (None, 19, 19, 816)  0          ['block5b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block5b_dwconv (DepthwiseConv2  (None, 19, 19, 816)  20400      ['block5b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block5b_bn (BatchNormalization  (None, 19, 19, 816)  3264       ['block5b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5b_activation (Activation  (None, 19, 19, 816)  0          ['block5b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5b_se_squeeze (GlobalAver  (None, 816)         0           ['block5b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5b_se_reshape (Reshape)   (None, 1, 1, 816)    0           ['block5b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_se_reduce (Conv2D)     (None, 1, 1, 34)     27778       ['block5b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_se_expand (Conv2D)     (None, 1, 1, 816)    28560       ['block5b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5b_se_excite (Multiply)   (None, 19, 19, 816)  0           ['block5b_activation[0][0]',     \n",
      "                                                                  'block5b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5b_project_conv (Conv2D)  (None, 19, 19, 136)  110976      ['block5b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5b_project_bn (BatchNorma  (None, 19, 19, 136)  544        ['block5b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5b_drop (Dropout)         (None, 19, 19, 136)  0           ['block5b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_add (Add)              (None, 19, 19, 136)  0           ['block5b_drop[0][0]',           \n",
      "                                                                  'block5a_project_bn[0][0]']     \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block5c_expand_conv (Conv2D)   (None, 19, 19, 816)  110976      ['block5b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5c_expand_bn (BatchNormal  (None, 19, 19, 816)  3264       ['block5c_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block5c_expand_activation (Act  (None, 19, 19, 816)  0          ['block5c_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block5c_dwconv (DepthwiseConv2  (None, 19, 19, 816)  20400      ['block5c_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block5c_bn (BatchNormalization  (None, 19, 19, 816)  3264       ['block5c_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5c_activation (Activation  (None, 19, 19, 816)  0          ['block5c_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5c_se_squeeze (GlobalAver  (None, 816)         0           ['block5c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5c_se_reshape (Reshape)   (None, 1, 1, 816)    0           ['block5c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_se_reduce (Conv2D)     (None, 1, 1, 34)     27778       ['block5c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_se_expand (Conv2D)     (None, 1, 1, 816)    28560       ['block5c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5c_se_excite (Multiply)   (None, 19, 19, 816)  0           ['block5c_activation[0][0]',     \n",
      "                                                                  'block5c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5c_project_conv (Conv2D)  (None, 19, 19, 136)  110976      ['block5c_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5c_project_bn (BatchNorma  (None, 19, 19, 136)  544        ['block5c_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5c_drop (Dropout)         (None, 19, 19, 136)  0           ['block5c_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_add (Add)              (None, 19, 19, 136)  0           ['block5c_drop[0][0]',           \n",
      "                                                                  'block5b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5d_expand_conv (Conv2D)   (None, 19, 19, 816)  110976      ['block5c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5d_expand_bn (BatchNormal  (None, 19, 19, 816)  3264       ['block5d_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block5d_expand_activation (Act  (None, 19, 19, 816)  0          ['block5d_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block5d_dwconv (DepthwiseConv2  (None, 19, 19, 816)  20400      ['block5d_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block5d_bn (BatchNormalization  (None, 19, 19, 816)  3264       ['block5d_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5d_activation (Activation  (None, 19, 19, 816)  0          ['block5d_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5d_se_squeeze (GlobalAver  (None, 816)         0           ['block5d_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5d_se_reshape (Reshape)   (None, 1, 1, 816)    0           ['block5d_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5d_se_reduce (Conv2D)     (None, 1, 1, 34)     27778       ['block5d_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5d_se_expand (Conv2D)     (None, 1, 1, 816)    28560       ['block5d_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5d_se_excite (Multiply)   (None, 19, 19, 816)  0           ['block5d_activation[0][0]',     \n",
      "                                                                  'block5d_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5d_project_conv (Conv2D)  (None, 19, 19, 136)  110976      ['block5d_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5d_project_bn (BatchNorma  (None, 19, 19, 136)  544        ['block5d_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5d_drop (Dropout)         (None, 19, 19, 136)  0           ['block5d_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5d_add (Add)              (None, 19, 19, 136)  0           ['block5d_drop[0][0]',           \n",
      "                                                                  'block5c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5e_expand_conv (Conv2D)   (None, 19, 19, 816)  110976      ['block5d_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5e_expand_bn (BatchNormal  (None, 19, 19, 816)  3264       ['block5e_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block5e_expand_activation (Act  (None, 19, 19, 816)  0          ['block5e_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block5e_dwconv (DepthwiseConv2  (None, 19, 19, 816)  20400      ['block5e_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block5e_bn (BatchNormalization  (None, 19, 19, 816)  3264       ['block5e_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5e_activation (Activation  (None, 19, 19, 816)  0          ['block5e_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5e_se_squeeze (GlobalAver  (None, 816)         0           ['block5e_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5e_se_reshape (Reshape)   (None, 1, 1, 816)    0           ['block5e_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5e_se_reduce (Conv2D)     (None, 1, 1, 34)     27778       ['block5e_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5e_se_expand (Conv2D)     (None, 1, 1, 816)    28560       ['block5e_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5e_se_excite (Multiply)   (None, 19, 19, 816)  0           ['block5e_activation[0][0]',     \n",
      "                                                                  'block5e_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5e_project_conv (Conv2D)  (None, 19, 19, 136)  110976      ['block5e_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5e_project_bn (BatchNorma  (None, 19, 19, 136)  544        ['block5e_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5e_drop (Dropout)         (None, 19, 19, 136)  0           ['block5e_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5e_add (Add)              (None, 19, 19, 136)  0           ['block5e_drop[0][0]',           \n",
      "                                                                  'block5d_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6a_expand_conv (Conv2D)   (None, 19, 19, 816)  110976      ['block5e_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6a_expand_bn (BatchNormal  (None, 19, 19, 816)  3264       ['block6a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6a_expand_activation (Act  (None, 19, 19, 816)  0          ['block6a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6a_dwconv_pad (ZeroPaddin  (None, 23, 23, 816)  0          ['block6a_expand_activation[0][0]\n",
      " g2D)                                                            ']                               \n",
      "                                                                                                  \n",
      " block6a_dwconv (DepthwiseConv2  (None, 10, 10, 816)  20400      ['block6a_dwconv_pad[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block6a_bn (BatchNormalization  (None, 10, 10, 816)  3264       ['block6a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6a_activation (Activation  (None, 10, 10, 816)  0          ['block6a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6a_se_squeeze (GlobalAver  (None, 816)         0           ['block6a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6a_se_reshape (Reshape)   (None, 1, 1, 816)    0           ['block6a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6a_se_reduce (Conv2D)     (None, 1, 1, 34)     27778       ['block6a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6a_se_expand (Conv2D)     (None, 1, 1, 816)    28560       ['block6a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6a_se_excite (Multiply)   (None, 10, 10, 816)  0           ['block6a_activation[0][0]',     \n",
      "                                                                  'block6a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6a_project_conv (Conv2D)  (None, 10, 10, 232)  189312      ['block6a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6a_project_bn (BatchNorma  (None, 10, 10, 232)  928        ['block6a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6b_expand_conv (Conv2D)   (None, 10, 10, 1392  322944      ['block6a_project_bn[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block6b_expand_bn (BatchNormal  (None, 10, 10, 1392  5568       ['block6b_expand_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block6b_expand_activation (Act  (None, 10, 10, 1392  0          ['block6b_expand_bn[0][0]']      \n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " block6b_dwconv (DepthwiseConv2  (None, 10, 10, 1392  34800      ['block6b_expand_activation[0][0]\n",
      " D)                             )                                ']                               \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block6b_bn (BatchNormalization  (None, 10, 10, 1392  5568       ['block6b_dwconv[0][0]']         \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block6b_activation (Activation  (None, 10, 10, 1392  0          ['block6b_bn[0][0]']             \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block6b_se_squeeze (GlobalAver  (None, 1392)        0           ['block6b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6b_se_reshape (Reshape)   (None, 1, 1, 1392)   0           ['block6b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_se_reduce (Conv2D)     (None, 1, 1, 58)     80794       ['block6b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_se_expand (Conv2D)     (None, 1, 1, 1392)   82128       ['block6b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6b_se_excite (Multiply)   (None, 10, 10, 1392  0           ['block6b_activation[0][0]',     \n",
      "                                )                                 'block6b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6b_project_conv (Conv2D)  (None, 10, 10, 232)  322944      ['block6b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6b_project_bn (BatchNorma  (None, 10, 10, 232)  928        ['block6b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6b_drop (Dropout)         (None, 10, 10, 232)  0           ['block6b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_add (Add)              (None, 10, 10, 232)  0           ['block6b_drop[0][0]',           \n",
      "                                                                  'block6a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_expand_conv (Conv2D)   (None, 10, 10, 1392  322944      ['block6b_add[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block6c_expand_bn (BatchNormal  (None, 10, 10, 1392  5568       ['block6c_expand_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block6c_expand_activation (Act  (None, 10, 10, 1392  0          ['block6c_expand_bn[0][0]']      \n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " block6c_dwconv (DepthwiseConv2  (None, 10, 10, 1392  34800      ['block6c_expand_activation[0][0]\n",
      " D)                             )                                ']                               \n",
      "                                                                                                  \n",
      " block6c_bn (BatchNormalization  (None, 10, 10, 1392  5568       ['block6c_dwconv[0][0]']         \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block6c_activation (Activation  (None, 10, 10, 1392  0          ['block6c_bn[0][0]']             \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block6c_se_squeeze (GlobalAver  (None, 1392)        0           ['block6c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6c_se_reshape (Reshape)   (None, 1, 1, 1392)   0           ['block6c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_se_reduce (Conv2D)     (None, 1, 1, 58)     80794       ['block6c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_se_expand (Conv2D)     (None, 1, 1, 1392)   82128       ['block6c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6c_se_excite (Multiply)   (None, 10, 10, 1392  0           ['block6c_activation[0][0]',     \n",
      "                                )                                 'block6c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6c_project_conv (Conv2D)  (None, 10, 10, 232)  322944      ['block6c_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6c_project_bn (BatchNorma  (None, 10, 10, 232)  928        ['block6c_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6c_drop (Dropout)         (None, 10, 10, 232)  0           ['block6c_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_add (Add)              (None, 10, 10, 232)  0           ['block6c_drop[0][0]',           \n",
      "                                                                  'block6b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6d_expand_conv (Conv2D)   (None, 10, 10, 1392  322944      ['block6c_add[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block6d_expand_bn (BatchNormal  (None, 10, 10, 1392  5568       ['block6d_expand_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block6d_expand_activation (Act  (None, 10, 10, 1392  0          ['block6d_expand_bn[0][0]']      \n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " block6d_dwconv (DepthwiseConv2  (None, 10, 10, 1392  34800      ['block6d_expand_activation[0][0]\n",
      " D)                             )                                ']                               \n",
      "                                                                                                  \n",
      " block6d_bn (BatchNormalization  (None, 10, 10, 1392  5568       ['block6d_dwconv[0][0]']         \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block6d_activation (Activation  (None, 10, 10, 1392  0          ['block6d_bn[0][0]']             \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block6d_se_squeeze (GlobalAver  (None, 1392)        0           ['block6d_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6d_se_reshape (Reshape)   (None, 1, 1, 1392)   0           ['block6d_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6d_se_reduce (Conv2D)     (None, 1, 1, 58)     80794       ['block6d_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6d_se_expand (Conv2D)     (None, 1, 1, 1392)   82128       ['block6d_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6d_se_excite (Multiply)   (None, 10, 10, 1392  0           ['block6d_activation[0][0]',     \n",
      "                                )                                 'block6d_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6d_project_conv (Conv2D)  (None, 10, 10, 232)  322944      ['block6d_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6d_project_bn (BatchNorma  (None, 10, 10, 232)  928        ['block6d_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6d_drop (Dropout)         (None, 10, 10, 232)  0           ['block6d_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6d_add (Add)              (None, 10, 10, 232)  0           ['block6d_drop[0][0]',           \n",
      "                                                                  'block6c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6e_expand_conv (Conv2D)   (None, 10, 10, 1392  322944      ['block6d_add[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block6e_expand_bn (BatchNormal  (None, 10, 10, 1392  5568       ['block6e_expand_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block6e_expand_activation (Act  (None, 10, 10, 1392  0          ['block6e_expand_bn[0][0]']      \n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " block6e_dwconv (DepthwiseConv2  (None, 10, 10, 1392  34800      ['block6e_expand_activation[0][0]\n",
      " D)                             )                                ']                               \n",
      "                                                                                                  \n",
      " block6e_bn (BatchNormalization  (None, 10, 10, 1392  5568       ['block6e_dwconv[0][0]']         \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block6e_activation (Activation  (None, 10, 10, 1392  0          ['block6e_bn[0][0]']             \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block6e_se_squeeze (GlobalAver  (None, 1392)        0           ['block6e_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6e_se_reshape (Reshape)   (None, 1, 1, 1392)   0           ['block6e_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6e_se_reduce (Conv2D)     (None, 1, 1, 58)     80794       ['block6e_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6e_se_expand (Conv2D)     (None, 1, 1, 1392)   82128       ['block6e_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6e_se_excite (Multiply)   (None, 10, 10, 1392  0           ['block6e_activation[0][0]',     \n",
      "                                )                                 'block6e_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6e_project_conv (Conv2D)  (None, 10, 10, 232)  322944      ['block6e_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6e_project_bn (BatchNorma  (None, 10, 10, 232)  928        ['block6e_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6e_drop (Dropout)         (None, 10, 10, 232)  0           ['block6e_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6e_add (Add)              (None, 10, 10, 232)  0           ['block6e_drop[0][0]',           \n",
      "                                                                  'block6d_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6f_expand_conv (Conv2D)   (None, 10, 10, 1392  322944      ['block6e_add[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block6f_expand_bn (BatchNormal  (None, 10, 10, 1392  5568       ['block6f_expand_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block6f_expand_activation (Act  (None, 10, 10, 1392  0          ['block6f_expand_bn[0][0]']      \n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " block6f_dwconv (DepthwiseConv2  (None, 10, 10, 1392  34800      ['block6f_expand_activation[0][0]\n",
      " D)                             )                                ']                               \n",
      "                                                                                                  \n",
      " block6f_bn (BatchNormalization  (None, 10, 10, 1392  5568       ['block6f_dwconv[0][0]']         \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block6f_activation (Activation  (None, 10, 10, 1392  0          ['block6f_bn[0][0]']             \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block6f_se_squeeze (GlobalAver  (None, 1392)        0           ['block6f_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6f_se_reshape (Reshape)   (None, 1, 1, 1392)   0           ['block6f_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6f_se_reduce (Conv2D)     (None, 1, 1, 58)     80794       ['block6f_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6f_se_expand (Conv2D)     (None, 1, 1, 1392)   82128       ['block6f_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6f_se_excite (Multiply)   (None, 10, 10, 1392  0           ['block6f_activation[0][0]',     \n",
      "                                )                                 'block6f_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6f_project_conv (Conv2D)  (None, 10, 10, 232)  322944      ['block6f_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6f_project_bn (BatchNorma  (None, 10, 10, 232)  928        ['block6f_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6f_drop (Dropout)         (None, 10, 10, 232)  0           ['block6f_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6f_add (Add)              (None, 10, 10, 232)  0           ['block6f_drop[0][0]',           \n",
      "                                                                  'block6e_add[0][0]']            \n",
      "                                                                                                  \n",
      " block7a_expand_conv (Conv2D)   (None, 10, 10, 1392  322944      ['block6f_add[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block7a_expand_bn (BatchNormal  (None, 10, 10, 1392  5568       ['block7a_expand_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block7a_expand_activation (Act  (None, 10, 10, 1392  0          ['block7a_expand_bn[0][0]']      \n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " block7a_dwconv (DepthwiseConv2  (None, 10, 10, 1392  12528      ['block7a_expand_activation[0][0]\n",
      " D)                             )                                ']                               \n",
      "                                                                                                  \n",
      " block7a_bn (BatchNormalization  (None, 10, 10, 1392  5568       ['block7a_dwconv[0][0]']         \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block7a_activation (Activation  (None, 10, 10, 1392  0          ['block7a_bn[0][0]']             \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block7a_se_squeeze (GlobalAver  (None, 1392)        0           ['block7a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block7a_se_reshape (Reshape)   (None, 1, 1, 1392)   0           ['block7a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block7a_se_reduce (Conv2D)     (None, 1, 1, 58)     80794       ['block7a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block7a_se_expand (Conv2D)     (None, 1, 1, 1392)   82128       ['block7a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block7a_se_excite (Multiply)   (None, 10, 10, 1392  0           ['block7a_activation[0][0]',     \n",
      "                                )                                 'block7a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block7a_project_conv (Conv2D)  (None, 10, 10, 384)  534528      ['block7a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block7a_project_bn (BatchNorma  (None, 10, 10, 384)  1536       ['block7a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block7b_expand_conv (Conv2D)   (None, 10, 10, 2304  884736      ['block7a_project_bn[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block7b_expand_bn (BatchNormal  (None, 10, 10, 2304  9216       ['block7b_expand_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block7b_expand_activation (Act  (None, 10, 10, 2304  0          ['block7b_expand_bn[0][0]']      \n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " block7b_dwconv (DepthwiseConv2  (None, 10, 10, 2304  20736      ['block7b_expand_activation[0][0]\n",
      " D)                             )                                ']                               \n",
      "                                                                                                  \n",
      " block7b_bn (BatchNormalization  (None, 10, 10, 2304  9216       ['block7b_dwconv[0][0]']         \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block7b_activation (Activation  (None, 10, 10, 2304  0          ['block7b_bn[0][0]']             \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block7b_se_squeeze (GlobalAver  (None, 2304)        0           ['block7b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block7b_se_reshape (Reshape)   (None, 1, 1, 2304)   0           ['block7b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block7b_se_reduce (Conv2D)     (None, 1, 1, 96)     221280      ['block7b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block7b_se_expand (Conv2D)     (None, 1, 1, 2304)   223488      ['block7b_se_reduce[0][0]']      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " block7b_se_excite (Multiply)   (None, 10, 10, 2304  0           ['block7b_activation[0][0]',     \n",
      "                                )                                 'block7b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block7b_project_conv (Conv2D)  (None, 10, 10, 384)  884736      ['block7b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block7b_project_bn (BatchNorma  (None, 10, 10, 384)  1536       ['block7b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block7b_drop (Dropout)         (None, 10, 10, 384)  0           ['block7b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block7b_add (Add)              (None, 10, 10, 384)  0           ['block7b_drop[0][0]',           \n",
      "                                                                  'block7a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " top_conv (Conv2D)              (None, 10, 10, 1536  589824      ['block7b_add[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " top_bn (BatchNormalization)    (None, 10, 10, 1536  6144        ['top_conv[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " top_activation (Activation)    (None, 10, 10, 1536  0           ['top_bn[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2 (Gl  (None, 1536)        0           ['top_activation[0][0]']         \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 1536)         0           ['global_average_pooling2d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 50)           76850       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10,860,385\n",
      "Trainable params: 10,773,082\n",
      "Non-trainable params: 87,303\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0383efd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T08:26:43.010797Z",
     "start_time": "2022-11-08T08:26:34.498325Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 08:26:34.791654: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-08 08:26:34.793243: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-08 08:26:34.793856: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-08 08:26:34.794395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-08 08:26:35.122740: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-08 08:26:35.123277: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-08 08:26:35.123765: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-08 08:26:35.124231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21922 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:09:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.python.keras.models import load_model\n",
    "\n",
    "\n",
    "model1_fold_1 = keras.models.load_model(base_path + '/fold1_EfficientNetB3_raw_2_4_best_221107.h5', custom_objects = {'f1score' : f1score} )\n",
    "model1_fold_2 = keras.models.load_model(base_path + '/fold2_EfficientNetB3_raw_2_4_best_221107.h5', custom_objects = {'f1score' : f1score} )\n",
    "#model1_fold_3 = keras.models.load_model(base_path + '/fold3_EfficientNetB3_raw_2_4_best_221107.h5', custom_objects = {'f1score' : f1score} )\n",
    "model1_fold_4 = keras.models.load_model(base_path + '/DACON_Artist_EfficientNet_12.hdf5', custom_objects = {'f1score' : f1score} )\n",
    "model1_fold_5 = keras.models.load_model(base_path + '/DACON_Artist_EfficientNet_13.hdf5', custom_objects = {'f1score' : f1score} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e630235",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T08:26:45.256833Z",
     "start_time": "2022-11-08T08:26:45.253090Z"
    }
   },
   "outputs": [],
   "source": [
    "def generator_predict(model, test_generator, batch_size=CFG['BATCH_SIZE']): # TTA를 위한 함수 정의\n",
    "\n",
    "    pred_list = []\n",
    "\n",
    "    pred_list.append(model.predict_generator(test_generator, # 기본적인 결과값\n",
    "                                         verbose=1\n",
    "                                        ))\n",
    "\n",
    "    predicted = np.mean(pred_list, axis=0)\n",
    "    return predicted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18957133",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T08:28:59.752016Z",
     "start_time": "2022-11-08T08:26:49.044538Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12670 validated image filenames.\n",
      "<keras.engine.functional.Functional object at 0x7fee005d1f90> model predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 08:26:50.863439: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4/396 [..............................] - ETA: 23s "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 08:26:52.099544: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396/396 [==============================] - 34s 79ms/step\n",
      "Found 12670 validated image filenames.\n",
      "<keras.engine.functional.Functional object at 0x7fed9a032f50> model predict\n",
      "396/396 [==============================] - 32s 78ms/step\n",
      "Found 12670 validated image filenames.\n",
      "<keras.engine.sequential.Sequential object at 0x7fed80342950> model predict\n",
      "396/396 [==============================] - 32s 78ms/step\n",
      "Found 12670 validated image filenames.\n",
      "<keras.engine.sequential.Sequential object at 0x7fed900cc5d0> model predict\n",
      "396/396 [==============================] - 32s 78ms/step\n"
     ]
    }
   ],
   "source": [
    "model_list = [model1_fold_1, model1_fold_2, model1_fold_4, model1_fold_5]\n",
    "model_pred = []\n",
    "labels = []\n",
    "\n",
    "for i, name in enumerate(model_list):\n",
    "    testgen = ImageDataGenerator()\n",
    "#                                   rescale=1./255,\n",
    "# #                                 featurewise_center=True,\n",
    "# #                                 featurewise_std_normalization=True,\n",
    "# #                                 rotation_range=20,\n",
    "# #                                 width_shift_range=0.2,\n",
    "# #                                 zoom_range = 0.5,\n",
    "# #                                 shear_range = 0.2,\n",
    "# #                                 height_shift_range=0.2,\n",
    "# #                                 horizontal_flip=True,\n",
    "# #                                 vertical_flip=True\n",
    "#                                 )\n",
    "    test_generator = testgen.flow_from_dataframe(test_csv, x_col='re_img_path', y_col=None, target_size=(CFG['IMG_SIZE'],CFG['IMG_SIZE']), batch_size=CFG['BATCH_SIZE'], seed=CFG['SEED'], shuffle=False, class_mode=None)\n",
    "    print('{} model predict'.format(name))\n",
    "    model_pred.append(generator_predict(name, test_generator, batch_size=CFG['BATCH_SIZE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6db4a192",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T08:28:59.762539Z",
     "start_time": "2022-11-08T08:28:59.754296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  2,  6, ...,  2, 46, 48])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = np.mean(model_pred, axis=0).argmax(1) # 5모델의 평균 \n",
    "predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a3fe212",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T08:28:59.765785Z",
     "start_time": "2022-11-08T08:28:59.763684Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = train_gen.class_indices\n",
    "\n",
    "new_labels = {}\n",
    "for k, v in labels.items():\n",
    "    new_labels[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06b4cbc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T08:28:59.780201Z",
     "start_time": "2022-11-08T08:28:59.767329Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Edgar Degas',\n",
       " 'Amedeo Modigliani',\n",
       " 'Caravaggio',\n",
       " 'Albrecht Du rer',\n",
       " 'Vincent van Gogh',\n",
       " 'Pablo Picasso',\n",
       " 'Pablo Picasso',\n",
       " 'Vincent van Gogh',\n",
       " 'Edouard Manet',\n",
       " 'Pieter Bruegel',\n",
       " 'Mikhail Vrubel',\n",
       " 'Rene Magritte',\n",
       " 'Vincent van Gogh',\n",
       " 'Edgar Degas',\n",
       " 'Sandro Botticelli',\n",
       " 'Diego Rivera',\n",
       " 'Frida Kahlo',\n",
       " 'Pablo Picasso',\n",
       " 'Giotto di Bondone',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Raphael',\n",
       " 'Henri Rousseau',\n",
       " 'Camille Pissarro',\n",
       " 'Eugene Delacroix',\n",
       " 'Amedeo Modigliani',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Vincent van Gogh',\n",
       " 'Vincent van Gogh',\n",
       " 'Salvador Dali',\n",
       " 'Henri de Toulouse-Lautrec',\n",
       " 'Frida Kahlo',\n",
       " 'Mikhail Vrubel',\n",
       " 'Diego Velazquez',\n",
       " 'Henri Matisse',\n",
       " 'Vincent van Gogh',\n",
       " 'Edgar Degas',\n",
       " 'Paul Gauguin',\n",
       " 'Andy Warhol',\n",
       " 'Henri Matisse',\n",
       " 'Titian',\n",
       " 'Giotto di Bondone',\n",
       " 'Sandro Botticelli',\n",
       " 'Gustav Klimt',\n",
       " 'Edgar Degas',\n",
       " 'Salvador Dali',\n",
       " 'Francisco Goya',\n",
       " 'Diego Velazquez',\n",
       " 'Francisco Goya',\n",
       " 'Paul Klee',\n",
       " 'Edgar Degas',\n",
       " 'Camille Pissarro',\n",
       " 'Vasiliy Kandinskiy',\n",
       " 'El Greco',\n",
       " 'Edgar Degas',\n",
       " 'Andrei Rublev',\n",
       " 'Amedeo Modigliani',\n",
       " 'Raphael',\n",
       " 'El Greco',\n",
       " 'Pablo Picasso',\n",
       " 'Gustav Klimt',\n",
       " 'Hieronymus Bosch',\n",
       " 'Paul Gauguin',\n",
       " 'Amedeo Modigliani',\n",
       " 'Francisco Goya',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Edgar Degas',\n",
       " 'Rene Magritte',\n",
       " 'Rembrandt',\n",
       " 'Edgar Degas',\n",
       " 'Titian',\n",
       " 'Edgar Degas',\n",
       " 'Albrecht Du rer',\n",
       " 'Sandro Botticelli',\n",
       " 'Mikhail Vrubel',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Francisco Goya',\n",
       " 'Edgar Degas',\n",
       " 'Marc Chagall',\n",
       " 'Andy Warhol',\n",
       " 'Vincent van Gogh',\n",
       " 'Paul Klee',\n",
       " 'Hieronymus Bosch',\n",
       " 'Edgar Degas',\n",
       " 'Claude Monet',\n",
       " 'Vincent van Gogh',\n",
       " 'Pablo Picasso',\n",
       " 'Titian',\n",
       " 'Pieter Bruegel',\n",
       " 'Henri de Toulouse-Lautrec',\n",
       " 'Rene Magritte',\n",
       " 'Joan Miro',\n",
       " 'Alfred Sisley',\n",
       " 'Kazimir Malevich',\n",
       " 'Joan Miro',\n",
       " 'Pieter Bruegel',\n",
       " 'Camille Pissarro',\n",
       " 'Pablo Picasso',\n",
       " 'Vincent van Gogh',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Alfred Sisley',\n",
       " 'Paul Gauguin',\n",
       " 'Marc Chagall',\n",
       " 'Henri Matisse',\n",
       " 'Giotto di Bondone',\n",
       " 'Sandro Botticelli',\n",
       " 'Caravaggio',\n",
       " 'Camille Pissarro',\n",
       " 'Vincent van Gogh',\n",
       " 'Alfred Sisley',\n",
       " 'Albrecht Du rer',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Edouard Manet',\n",
       " 'Henri Matisse',\n",
       " 'Jan van Eyck',\n",
       " 'Edvard Munch',\n",
       " 'Diego Rivera',\n",
       " 'Pablo Picasso',\n",
       " 'Raphael',\n",
       " 'Georges Seurat',\n",
       " 'Andy Warhol',\n",
       " 'Amedeo Modigliani',\n",
       " 'Andrei Rublev',\n",
       " 'Rembrandt',\n",
       " 'Rene Magritte',\n",
       " 'Peter Paul Rubens',\n",
       " 'Leonardo da Vinci',\n",
       " 'Vincent van Gogh',\n",
       " 'Diego Velazquez',\n",
       " 'Rembrandt',\n",
       " 'Alfred Sisley',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Piet Mondrian',\n",
       " 'Pablo Picasso',\n",
       " 'Diego Velazquez',\n",
       " 'Leonardo da Vinci',\n",
       " 'Pablo Picasso',\n",
       " 'Alfred Sisley',\n",
       " 'Mikhail Vrubel',\n",
       " 'Titian',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Diego Velazquez',\n",
       " 'Alfred Sisley',\n",
       " 'Albrecht Du rer',\n",
       " 'Alfred Sisley',\n",
       " 'Edgar Degas',\n",
       " 'Vasiliy Kandinskiy',\n",
       " 'Peter Paul Rubens',\n",
       " 'Vincent van Gogh',\n",
       " 'Alfred Sisley',\n",
       " 'Alfred Sisley',\n",
       " 'Peter Paul Rubens',\n",
       " 'Edgar Degas',\n",
       " 'Edgar Degas',\n",
       " 'Alfred Sisley',\n",
       " 'Titian',\n",
       " 'Leonardo da Vinci',\n",
       " 'Frida Kahlo',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Raphael',\n",
       " 'Andrei Rublev',\n",
       " 'Francisco Goya',\n",
       " 'Vincent van Gogh',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Pablo Picasso',\n",
       " 'Paul Cezanne',\n",
       " 'Albrecht Du rer',\n",
       " 'Edgar Degas',\n",
       " 'Henri Matisse',\n",
       " 'Vincent van Gogh',\n",
       " 'Vincent van Gogh',\n",
       " 'Edouard Manet',\n",
       " 'Edgar Degas',\n",
       " 'Henri de Toulouse-Lautrec',\n",
       " 'Salvador Dali',\n",
       " 'Paul Gauguin',\n",
       " 'Edouard Manet',\n",
       " 'Albrecht Du rer',\n",
       " 'Albrecht Du rer',\n",
       " 'Rembrandt',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Rembrandt',\n",
       " 'Francisco Goya',\n",
       " 'Edgar Degas',\n",
       " 'Edgar Degas',\n",
       " 'Albrecht Du rer',\n",
       " 'Pablo Picasso',\n",
       " 'Edgar Degas',\n",
       " 'Diego Rivera',\n",
       " 'Paul Gauguin',\n",
       " 'Henri Matisse',\n",
       " 'Francisco Goya',\n",
       " 'Giotto di Bondone',\n",
       " 'Marc Chagall',\n",
       " 'Pieter Bruegel',\n",
       " 'Pieter Bruegel',\n",
       " 'Alfred Sisley',\n",
       " 'Edgar Degas',\n",
       " 'Francisco Goya',\n",
       " 'Albrecht Du rer',\n",
       " 'Marc Chagall',\n",
       " 'Francisco Goya',\n",
       " 'Alfred Sisley',\n",
       " 'Edgar Degas',\n",
       " 'Alfred Sisley',\n",
       " 'Henri Matisse',\n",
       " 'Andy Warhol',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Albrecht Du rer',\n",
       " 'Vincent van Gogh',\n",
       " 'Edgar Degas',\n",
       " 'Albrecht Du rer',\n",
       " 'Paul Gauguin',\n",
       " 'Mikhail Vrubel',\n",
       " 'Caravaggio',\n",
       " 'Hieronymus Bosch',\n",
       " 'Edgar Degas',\n",
       " 'Edgar Degas',\n",
       " 'Edgar Degas',\n",
       " 'Amedeo Modigliani',\n",
       " 'Francisco Goya',\n",
       " 'Vincent van Gogh',\n",
       " 'Vincent van Gogh',\n",
       " 'Edgar Degas',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Alfred Sisley',\n",
       " 'Marc Chagall',\n",
       " 'Vincent van Gogh',\n",
       " 'Vasiliy Kandinskiy',\n",
       " 'Mikhail Vrubel',\n",
       " 'Frida Kahlo',\n",
       " 'Hieronymus Bosch',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Paul Gauguin',\n",
       " 'Vasiliy Kandinskiy',\n",
       " 'Andy Warhol',\n",
       " 'Pablo Picasso',\n",
       " 'Henri Matisse',\n",
       " 'Caravaggio',\n",
       " 'Paul Gauguin',\n",
       " 'Edgar Degas',\n",
       " 'Claude Monet',\n",
       " 'Pablo Picasso',\n",
       " 'Amedeo Modigliani',\n",
       " 'Edgar Degas',\n",
       " 'Edgar Degas',\n",
       " 'Diego Rivera',\n",
       " 'Piet Mondrian',\n",
       " 'Francisco Goya',\n",
       " 'Albrecht Du rer',\n",
       " 'El Greco',\n",
       " 'Leonardo da Vinci',\n",
       " 'Pablo Picasso',\n",
       " 'Hieronymus Bosch',\n",
       " 'El Greco',\n",
       " 'Sandro Botticelli',\n",
       " 'Vincent van Gogh',\n",
       " 'El Greco',\n",
       " 'Salvador Dali',\n",
       " 'Edouard Manet',\n",
       " 'Leonardo da Vinci',\n",
       " 'Francisco Goya',\n",
       " 'Vincent van Gogh',\n",
       " 'Paul Klee',\n",
       " 'Vincent van Gogh',\n",
       " 'Alfred Sisley',\n",
       " 'Raphael',\n",
       " 'Edgar Degas',\n",
       " 'Pablo Picasso',\n",
       " 'Marc Chagall',\n",
       " 'Diego Rivera',\n",
       " 'Diego Velazquez',\n",
       " 'Kazimir Malevich',\n",
       " 'Edouard Manet',\n",
       " 'Rembrandt',\n",
       " 'Albrecht Du rer',\n",
       " 'Amedeo Modigliani',\n",
       " 'Edvard Munch',\n",
       " 'Albrecht Du rer',\n",
       " 'Joan Miro',\n",
       " 'Pablo Picasso',\n",
       " 'Andy Warhol',\n",
       " 'Pablo Picasso',\n",
       " 'Titian',\n",
       " 'Henri Matisse',\n",
       " 'Raphael',\n",
       " 'Gustav Klimt',\n",
       " 'Caravaggio',\n",
       " 'Vincent van Gogh',\n",
       " 'Pablo Picasso',\n",
       " 'Paul Klee',\n",
       " 'Paul Gauguin',\n",
       " 'Andy Warhol',\n",
       " 'Vincent van Gogh',\n",
       " 'Amedeo Modigliani',\n",
       " 'Edouard Manet',\n",
       " 'Edouard Manet',\n",
       " 'Mikhail Vrubel',\n",
       " 'Rembrandt',\n",
       " 'Pieter Bruegel',\n",
       " 'Frida Kahlo',\n",
       " 'Rene Magritte',\n",
       " 'Edvard Munch',\n",
       " 'Jan van Eyck',\n",
       " 'Camille Pissarro',\n",
       " 'Amedeo Modigliani',\n",
       " 'Edgar Degas',\n",
       " 'Peter Paul Rubens',\n",
       " 'Edgar Degas',\n",
       " 'Mikhail Vrubel',\n",
       " 'Andy Warhol',\n",
       " 'Andy Warhol',\n",
       " 'Edgar Degas',\n",
       " 'Alfred Sisley',\n",
       " 'Pieter Bruegel',\n",
       " 'Alfred Sisley',\n",
       " 'Peter Paul Rubens',\n",
       " 'El Greco',\n",
       " 'Michelangelo',\n",
       " 'Vincent van Gogh',\n",
       " 'Alfred Sisley',\n",
       " 'Edgar Degas',\n",
       " 'Paul Gauguin',\n",
       " 'Vincent van Gogh',\n",
       " 'Rembrandt',\n",
       " 'El Greco',\n",
       " 'Peter Paul Rubens',\n",
       " 'Edgar Degas',\n",
       " 'Edgar Degas',\n",
       " 'Titian',\n",
       " 'Pablo Picasso',\n",
       " 'Gustav Klimt',\n",
       " 'Peter Paul Rubens',\n",
       " 'Diego Velazquez',\n",
       " 'Edgar Degas',\n",
       " 'Alfred Sisley',\n",
       " 'Alfred Sisley',\n",
       " 'Albrecht Du rer',\n",
       " 'Vincent van Gogh',\n",
       " 'Pieter Bruegel',\n",
       " 'Henri Matisse',\n",
       " 'Vincent van Gogh',\n",
       " 'Pablo Picasso',\n",
       " 'Paul Gauguin',\n",
       " 'Francisco Goya',\n",
       " 'Vincent van Gogh',\n",
       " 'Giotto di Bondone',\n",
       " 'Rene Magritte',\n",
       " 'Jan van Eyck',\n",
       " 'Vincent van Gogh',\n",
       " 'Rene Magritte',\n",
       " 'Giotto di Bondone',\n",
       " 'Mikhail Vrubel',\n",
       " 'Salvador Dali',\n",
       " 'Albrecht Du rer',\n",
       " 'Vincent van Gogh',\n",
       " 'Vincent van Gogh',\n",
       " 'Raphael',\n",
       " 'Raphael',\n",
       " 'Amedeo Modigliani',\n",
       " 'Piet Mondrian',\n",
       " 'Jan van Eyck',\n",
       " 'Edouard Manet',\n",
       " 'Henri Matisse',\n",
       " 'Camille Pissarro',\n",
       " 'Frida Kahlo',\n",
       " 'Mikhail Vrubel',\n",
       " 'Sandro Botticelli',\n",
       " 'Alfred Sisley',\n",
       " 'Vincent van Gogh',\n",
       " 'Andy Warhol',\n",
       " 'Vincent van Gogh',\n",
       " 'Pablo Picasso',\n",
       " 'Francisco Goya',\n",
       " 'Rembrandt',\n",
       " 'Paul Gauguin',\n",
       " 'Titian',\n",
       " 'Andy Warhol',\n",
       " 'Frida Kahlo',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Pieter Bruegel',\n",
       " 'Diego Rivera',\n",
       " 'Paul Klee',\n",
       " 'Rene Magritte',\n",
       " 'Salvador Dali',\n",
       " 'Titian',\n",
       " 'Salvador Dali',\n",
       " 'Pablo Picasso',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Paul Gauguin',\n",
       " 'Edgar Degas',\n",
       " 'Edgar Degas',\n",
       " 'Pablo Picasso',\n",
       " 'Pieter Bruegel',\n",
       " 'Paul Gauguin',\n",
       " 'Mikhail Vrubel',\n",
       " 'Alfred Sisley',\n",
       " 'Alfred Sisley',\n",
       " 'Edgar Degas',\n",
       " 'Kazimir Malevich',\n",
       " 'Alfred Sisley',\n",
       " 'Marc Chagall',\n",
       " 'Alfred Sisley',\n",
       " 'Raphael',\n",
       " 'Vincent van Gogh',\n",
       " 'Pablo Picasso',\n",
       " 'Edgar Degas',\n",
       " 'Gustav Klimt',\n",
       " 'Pablo Picasso',\n",
       " 'Vincent van Gogh',\n",
       " 'Pablo Picasso',\n",
       " 'Vincent van Gogh',\n",
       " 'Edgar Degas',\n",
       " 'Pablo Picasso',\n",
       " 'Diego Velazquez',\n",
       " 'Diego Velazquez',\n",
       " 'Alfred Sisley',\n",
       " 'Camille Pissarro',\n",
       " 'Henri Matisse',\n",
       " 'Jackson Pollock',\n",
       " 'Vincent van Gogh',\n",
       " 'Vincent van Gogh',\n",
       " 'Albrecht Du rer',\n",
       " 'Raphael',\n",
       " 'Sandro Botticelli',\n",
       " 'Diego Velazquez',\n",
       " 'Titian',\n",
       " 'Salvador Dali',\n",
       " 'Amedeo Modigliani',\n",
       " 'Rene Magritte',\n",
       " 'Albrecht Du rer',\n",
       " 'Gustave Courbet',\n",
       " 'El Greco',\n",
       " 'Marc Chagall',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Giotto di Bondone',\n",
       " 'Mikhail Vrubel',\n",
       " 'Andy Warhol',\n",
       " 'Edgar Degas',\n",
       " 'Vincent van Gogh',\n",
       " 'Andy Warhol',\n",
       " 'Kazimir Malevich',\n",
       " 'Pablo Picasso',\n",
       " 'Mikhail Vrubel',\n",
       " 'Diego Rivera',\n",
       " 'Edgar Degas',\n",
       " 'Albrecht Du rer',\n",
       " 'Edouard Manet',\n",
       " 'Francisco Goya',\n",
       " 'Vasiliy Kandinskiy',\n",
       " 'Peter Paul Rubens',\n",
       " 'Mikhail Vrubel',\n",
       " 'Amedeo Modigliani',\n",
       " 'Joan Miro',\n",
       " 'Peter Paul Rubens',\n",
       " 'Marc Chagall',\n",
       " 'Sandro Botticelli',\n",
       " 'Edgar Degas',\n",
       " 'Kazimir Malevich',\n",
       " 'Gustav Klimt',\n",
       " 'Pieter Bruegel',\n",
       " 'Vincent van Gogh',\n",
       " 'Paul Gauguin',\n",
       " 'Francisco Goya',\n",
       " 'Marc Chagall',\n",
       " 'Vincent van Gogh',\n",
       " 'Pablo Picasso',\n",
       " 'Henri Matisse',\n",
       " 'Albrecht Du rer',\n",
       " 'Salvador Dali',\n",
       " 'Edgar Degas',\n",
       " 'Amedeo Modigliani',\n",
       " 'Marc Chagall',\n",
       " 'Peter Paul Rubens',\n",
       " 'Pablo Picasso',\n",
       " 'Frida Kahlo',\n",
       " 'Vincent van Gogh',\n",
       " 'Albrecht Du rer',\n",
       " 'Peter Paul Rubens',\n",
       " 'Camille Pissarro',\n",
       " 'Amedeo Modigliani',\n",
       " 'Giotto di Bondone',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Piet Mondrian',\n",
       " 'William Turner',\n",
       " 'Camille Pissarro',\n",
       " 'Kazimir Malevich',\n",
       " 'Vincent van Gogh',\n",
       " 'Hieronymus Bosch',\n",
       " 'Rembrandt',\n",
       " 'Rene Magritte',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Henri Rousseau',\n",
       " 'Rene Magritte',\n",
       " 'Edgar Degas',\n",
       " 'Alfred Sisley',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Pablo Picasso',\n",
       " 'Pablo Picasso',\n",
       " 'Joan Miro',\n",
       " 'Hieronymus Bosch',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'El Greco',\n",
       " 'Vincent van Gogh',\n",
       " 'Vincent van Gogh',\n",
       " 'Paul Klee',\n",
       " 'Pablo Picasso',\n",
       " 'Vincent van Gogh',\n",
       " 'Mikhail Vrubel',\n",
       " 'Titian',\n",
       " 'Francisco Goya',\n",
       " 'Pablo Picasso',\n",
       " 'Andy Warhol',\n",
       " 'Pablo Picasso',\n",
       " 'Vincent van Gogh',\n",
       " 'Edgar Degas',\n",
       " 'Alfred Sisley',\n",
       " 'Alfred Sisley',\n",
       " 'Rembrandt',\n",
       " 'Giotto di Bondone',\n",
       " 'Henri Matisse',\n",
       " 'Kazimir Malevich',\n",
       " 'Kazimir Malevich',\n",
       " 'Paul Klee',\n",
       " 'Mikhail Vrubel',\n",
       " 'Vincent van Gogh',\n",
       " 'Jan van Eyck',\n",
       " 'Edgar Degas',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Albrecht Du rer',\n",
       " 'Vincent van Gogh',\n",
       " 'Camille Pissarro',\n",
       " 'Edvard Munch',\n",
       " 'Titian',\n",
       " 'Alfred Sisley',\n",
       " 'Rembrandt',\n",
       " 'Vincent van Gogh',\n",
       " 'Marc Chagall',\n",
       " 'Hieronymus Bosch',\n",
       " 'Rene Magritte',\n",
       " 'Michelangelo',\n",
       " 'Pablo Picasso',\n",
       " 'Albrecht Du rer',\n",
       " 'Rene Magritte',\n",
       " 'Michelangelo',\n",
       " 'Vincent van Gogh',\n",
       " 'Caravaggio',\n",
       " 'Pablo Picasso',\n",
       " 'Giotto di Bondone',\n",
       " 'Titian',\n",
       " 'Vincent van Gogh',\n",
       " 'Rene Magritte',\n",
       " 'Vincent van Gogh',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Henri Rousseau',\n",
       " 'Vincent van Gogh',\n",
       " 'Pablo Picasso',\n",
       " 'Edgar Degas',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Diego Velazquez',\n",
       " 'Paul Gauguin',\n",
       " 'Paul Gauguin',\n",
       " 'Henri Matisse',\n",
       " 'El Greco',\n",
       " 'Edouard Manet',\n",
       " 'Sandro Botticelli',\n",
       " 'Alfred Sisley',\n",
       " 'Rembrandt',\n",
       " 'Sandro Botticelli',\n",
       " 'Joan Miro',\n",
       " 'Edgar Degas',\n",
       " 'Mikhail Vrubel',\n",
       " 'Vincent van Gogh',\n",
       " 'Leonardo da Vinci',\n",
       " 'Marc Chagall',\n",
       " 'Albrecht Du rer',\n",
       " 'Albrecht Du rer',\n",
       " 'Marc Chagall',\n",
       " 'Vincent van Gogh',\n",
       " 'Rembrandt',\n",
       " 'Vincent van Gogh',\n",
       " 'Vincent van Gogh',\n",
       " 'Paul Klee',\n",
       " 'Vincent van Gogh',\n",
       " 'Albrecht Du rer',\n",
       " 'Andy Warhol',\n",
       " 'Amedeo Modigliani',\n",
       " 'Salvador Dali',\n",
       " 'Alfred Sisley',\n",
       " 'Vincent van Gogh',\n",
       " 'Raphael',\n",
       " 'Andy Warhol',\n",
       " 'Amedeo Modigliani',\n",
       " 'Giotto di Bondone',\n",
       " 'Sandro Botticelli',\n",
       " 'Alfred Sisley',\n",
       " 'Marc Chagall',\n",
       " 'Francisco Goya',\n",
       " 'Diego Velazquez',\n",
       " 'Henri Rousseau',\n",
       " 'Amedeo Modigliani',\n",
       " 'Amedeo Modigliani',\n",
       " 'Diego Velazquez',\n",
       " 'Francisco Goya',\n",
       " 'Kazimir Malevich',\n",
       " 'Vasiliy Kandinskiy',\n",
       " 'Diego Velazquez',\n",
       " 'Pablo Picasso',\n",
       " 'Edgar Degas',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Salvador Dali',\n",
       " 'Georges Seurat',\n",
       " 'Vincent van Gogh',\n",
       " 'Giotto di Bondone',\n",
       " 'Frida Kahlo',\n",
       " 'Henri Matisse',\n",
       " 'Francisco Goya',\n",
       " 'Vincent van Gogh',\n",
       " 'Gustav Klimt',\n",
       " 'Edgar Degas',\n",
       " 'Vincent van Gogh',\n",
       " 'Edgar Degas',\n",
       " 'Francisco Goya',\n",
       " 'Mikhail Vrubel',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Camille Pissarro',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Paul Cezanne',\n",
       " 'Paul Klee',\n",
       " 'Paul Klee',\n",
       " 'Mikhail Vrubel',\n",
       " 'Vincent van Gogh',\n",
       " 'Andrei Rublev',\n",
       " 'Vincent van Gogh',\n",
       " 'Frida Kahlo',\n",
       " 'Peter Paul Rubens',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Titian',\n",
       " 'William Turner',\n",
       " 'Edgar Degas',\n",
       " 'Claude Monet',\n",
       " 'Edouard Manet',\n",
       " 'Edgar Degas',\n",
       " 'Andrei Rublev',\n",
       " 'Salvador Dali',\n",
       " 'Vincent van Gogh',\n",
       " 'Frida Kahlo',\n",
       " 'Sandro Botticelli',\n",
       " 'Edvard Munch',\n",
       " 'Diego Velazquez',\n",
       " 'Paul Klee',\n",
       " 'Alfred Sisley',\n",
       " 'Marc Chagall',\n",
       " 'Giotto di Bondone',\n",
       " 'Camille Pissarro',\n",
       " 'Alfred Sisley',\n",
       " 'Albrecht Du rer',\n",
       " 'Edgar Degas',\n",
       " 'Titian',\n",
       " 'Rembrandt',\n",
       " 'Kazimir Malevich',\n",
       " 'Henri Matisse',\n",
       " 'Mikhail Vrubel',\n",
       " 'Georges Seurat',\n",
       " 'Henri Matisse',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Paul Gauguin',\n",
       " 'Giotto di Bondone',\n",
       " 'Amedeo Modigliani',\n",
       " 'Edgar Degas',\n",
       " 'Alfred Sisley',\n",
       " 'Pablo Picasso',\n",
       " 'Pablo Picasso',\n",
       " 'Gustav Klimt',\n",
       " 'Edgar Degas',\n",
       " 'Vincent van Gogh',\n",
       " 'Paul Klee',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Hieronymus Bosch',\n",
       " 'Paul Gauguin',\n",
       " 'Rembrandt',\n",
       " 'Albrecht Du rer',\n",
       " 'Alfred Sisley',\n",
       " 'Vincent van Gogh',\n",
       " 'Vincent van Gogh',\n",
       " 'Vincent van Gogh',\n",
       " 'Marc Chagall',\n",
       " 'Albrecht Du rer',\n",
       " 'Camille Pissarro',\n",
       " 'Caravaggio',\n",
       " 'Diego Rivera',\n",
       " 'Pablo Picasso',\n",
       " 'Pablo Picasso',\n",
       " 'Paul Gauguin',\n",
       " 'Vincent van Gogh',\n",
       " 'Jan van Eyck',\n",
       " 'Henri Matisse',\n",
       " 'Marc Chagall',\n",
       " 'Alfred Sisley',\n",
       " 'Marc Chagall',\n",
       " 'Vincent van Gogh',\n",
       " 'Rene Magritte',\n",
       " 'Francisco Goya',\n",
       " 'Alfred Sisley',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Edgar Degas',\n",
       " 'Vincent van Gogh',\n",
       " 'Vincent van Gogh',\n",
       " 'Albrecht Du rer',\n",
       " 'Vincent van Gogh',\n",
       " 'Francisco Goya',\n",
       " 'Peter Paul Rubens',\n",
       " 'Salvador Dali',\n",
       " 'Vincent van Gogh',\n",
       " 'Raphael',\n",
       " 'Diego Velazquez',\n",
       " 'Paul Gauguin',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Andy Warhol',\n",
       " 'Edgar Degas',\n",
       " 'Paul Gauguin',\n",
       " 'Rembrandt',\n",
       " 'Raphael',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Piet Mondrian',\n",
       " 'Amedeo Modigliani',\n",
       " 'Joan Miro',\n",
       " 'Amedeo Modigliani',\n",
       " 'Marc Chagall',\n",
       " 'Giotto di Bondone',\n",
       " 'Vasiliy Kandinskiy',\n",
       " 'Edgar Degas',\n",
       " 'Mikhail Vrubel',\n",
       " 'Pablo Picasso',\n",
       " 'Raphael',\n",
       " 'Peter Paul Rubens',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Giotto di Bondone',\n",
       " 'Diego Velazquez',\n",
       " 'Vincent van Gogh',\n",
       " 'Edgar Degas',\n",
       " 'Henri Matisse',\n",
       " 'Rene Magritte',\n",
       " 'Edouard Manet',\n",
       " 'Edgar Degas',\n",
       " 'Vincent van Gogh',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Diego Rivera',\n",
       " 'Peter Paul Rubens',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Alfred Sisley',\n",
       " 'Vincent van Gogh',\n",
       " 'Joan Miro',\n",
       " 'Edgar Degas',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Edgar Degas',\n",
       " 'Piet Mondrian',\n",
       " 'Marc Chagall',\n",
       " 'Sandro Botticelli',\n",
       " 'Edgar Degas',\n",
       " 'Edouard Manet',\n",
       " 'Gustave Courbet',\n",
       " 'Rembrandt',\n",
       " 'Hieronymus Bosch',\n",
       " 'Gustave Courbet',\n",
       " 'Amedeo Modigliani',\n",
       " 'William Turner',\n",
       " 'Marc Chagall',\n",
       " 'Pablo Picasso',\n",
       " 'Edgar Degas',\n",
       " 'Vincent van Gogh',\n",
       " 'Peter Paul Rubens',\n",
       " 'Francisco Goya',\n",
       " 'Francisco Goya',\n",
       " 'Edgar Degas',\n",
       " 'Pablo Picasso',\n",
       " 'Vincent van Gogh',\n",
       " 'Vincent van Gogh',\n",
       " 'Marc Chagall',\n",
       " 'Amedeo Modigliani',\n",
       " 'Alfred Sisley',\n",
       " 'Pablo Picasso',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Edgar Degas',\n",
       " 'Albrecht Du rer',\n",
       " 'Marc Chagall',\n",
       " 'El Greco',\n",
       " 'Andrei Rublev',\n",
       " 'Peter Paul Rubens',\n",
       " 'Vincent van Gogh',\n",
       " 'Andy Warhol',\n",
       " 'Edgar Degas',\n",
       " 'Leonardo da Vinci',\n",
       " 'El Greco',\n",
       " 'Diego Rivera',\n",
       " 'Amedeo Modigliani',\n",
       " 'Pablo Picasso',\n",
       " 'Peter Paul Rubens',\n",
       " 'Caravaggio',\n",
       " 'Pablo Picasso',\n",
       " 'Mikhail Vrubel',\n",
       " 'Amedeo Modigliani',\n",
       " 'Alfred Sisley',\n",
       " 'Pablo Picasso',\n",
       " 'Sandro Botticelli',\n",
       " 'Andy Warhol',\n",
       " 'Leonardo da Vinci',\n",
       " 'Pieter Bruegel',\n",
       " 'Kazimir Malevich',\n",
       " 'Vincent van Gogh',\n",
       " 'Leonardo da Vinci',\n",
       " 'Titian',\n",
       " 'Pablo Picasso',\n",
       " 'Albrecht Du rer',\n",
       " 'Rene Magritte',\n",
       " 'Vincent van Gogh',\n",
       " 'Paul Gauguin',\n",
       " 'Alfred Sisley',\n",
       " 'Vincent van Gogh',\n",
       " 'Pieter Bruegel',\n",
       " 'Hieronymus Bosch',\n",
       " 'Albrecht Du rer',\n",
       " 'Edgar Degas',\n",
       " 'Edgar Degas',\n",
       " 'Francisco Goya',\n",
       " 'Titian',\n",
       " 'Alfred Sisley',\n",
       " 'Alfred Sisley',\n",
       " 'Pablo Picasso',\n",
       " 'Caravaggio',\n",
       " 'Salvador Dali',\n",
       " 'Rene Magritte',\n",
       " 'Diego Velazquez',\n",
       " 'Pablo Picasso',\n",
       " 'Titian',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Vincent van Gogh',\n",
       " 'Edgar Degas',\n",
       " 'Edgar Degas',\n",
       " 'Jan van Eyck',\n",
       " 'Titian',\n",
       " 'Pablo Picasso',\n",
       " 'Giotto di Bondone',\n",
       " 'Albrecht Du rer',\n",
       " 'Albrecht Du rer',\n",
       " 'Vincent van Gogh',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Edgar Degas',\n",
       " 'Henri Matisse',\n",
       " 'Rembrandt',\n",
       " 'Hieronymus Bosch',\n",
       " 'Frida Kahlo',\n",
       " 'Paul Gauguin',\n",
       " 'Albrecht Du rer',\n",
       " 'Alfred Sisley',\n",
       " 'Andrei Rublev',\n",
       " 'Jackson Pollock',\n",
       " 'Claude Monet',\n",
       " 'Albrecht Du rer',\n",
       " 'Edgar Degas',\n",
       " 'Raphael',\n",
       " 'Caravaggio',\n",
       " 'Pablo Picasso',\n",
       " 'Edgar Degas',\n",
       " 'Rembrandt',\n",
       " 'Piet Mondrian',\n",
       " 'Vincent van Gogh',\n",
       " 'Pieter Bruegel',\n",
       " 'Edgar Degas',\n",
       " 'Vasiliy Kandinskiy',\n",
       " 'Mikhail Vrubel',\n",
       " 'Francisco Goya',\n",
       " 'Peter Paul Rubens',\n",
       " 'Hieronymus Bosch',\n",
       " 'Vincent van Gogh',\n",
       " 'Alfred Sisley',\n",
       " 'Albrecht Du rer',\n",
       " 'Edgar Degas',\n",
       " 'Joan Miro',\n",
       " 'Giotto di Bondone',\n",
       " 'Henri de Toulouse-Lautrec',\n",
       " 'Henri Rousseau',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Henri Matisse',\n",
       " 'Joan Miro',\n",
       " 'Paul Gauguin',\n",
       " 'Titian',\n",
       " 'Henri Matisse',\n",
       " 'Edgar Degas',\n",
       " 'Vincent van Gogh',\n",
       " 'Rene Magritte',\n",
       " 'Edgar Degas',\n",
       " 'Pieter Bruegel',\n",
       " 'Paul Gauguin',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Edgar Degas',\n",
       " 'Vincent van Gogh',\n",
       " 'Joan Miro',\n",
       " 'Edgar Degas',\n",
       " 'Marc Chagall',\n",
       " 'Albrecht Du rer',\n",
       " 'Sandro Botticelli',\n",
       " 'Salvador Dali',\n",
       " 'Kazimir Malevich',\n",
       " 'Titian',\n",
       " 'Edgar Degas',\n",
       " 'Gustave Courbet',\n",
       " 'Pieter Bruegel',\n",
       " 'Edgar Degas',\n",
       " 'Pablo Picasso',\n",
       " 'Paul Gauguin',\n",
       " 'Henri Rousseau',\n",
       " 'Raphael',\n",
       " 'Pablo Picasso',\n",
       " 'Joan Miro',\n",
       " 'Vincent van Gogh',\n",
       " 'Vincent van Gogh',\n",
       " 'Francisco Goya',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Gustav Klimt',\n",
       " 'Rembrandt',\n",
       " 'Vincent van Gogh',\n",
       " 'Titian',\n",
       " 'Rene Magritte',\n",
       " 'Albrecht Du rer',\n",
       " 'Vasiliy Kandinskiy',\n",
       " 'Vincent van Gogh',\n",
       " 'Georges Seurat',\n",
       " 'Eugene Delacroix',\n",
       " 'Paul Cezanne',\n",
       " 'Edvard Munch',\n",
       " 'Pablo Picasso',\n",
       " 'Vincent van Gogh',\n",
       " 'Giotto di Bondone',\n",
       " 'Vincent van Gogh',\n",
       " 'Giotto di Bondone',\n",
       " 'Vincent van Gogh',\n",
       " 'Francisco Goya',\n",
       " 'Edvard Munch',\n",
       " 'Salvador Dali',\n",
       " 'Francisco Goya',\n",
       " 'Vincent van Gogh',\n",
       " 'Francisco Goya',\n",
       " 'Alfred Sisley',\n",
       " 'Kazimir Malevich',\n",
       " 'Henri Matisse',\n",
       " 'Edgar Degas',\n",
       " 'Kazimir Malevich',\n",
       " 'Pablo Picasso',\n",
       " 'Edgar Degas',\n",
       " 'Andrei Rublev',\n",
       " 'Albrecht Du rer',\n",
       " 'Frida Kahlo',\n",
       " 'Gustav Klimt',\n",
       " 'Titian',\n",
       " 'Edgar Degas',\n",
       " 'Paul Gauguin',\n",
       " 'Peter Paul Rubens',\n",
       " 'Amedeo Modigliani',\n",
       " 'Edgar Degas',\n",
       " 'Paul Klee',\n",
       " 'Henri Matisse',\n",
       " 'Caravaggio',\n",
       " 'Pablo Picasso',\n",
       " 'Edgar Degas',\n",
       " 'Gustav Klimt',\n",
       " 'Edgar Degas',\n",
       " 'Titian',\n",
       " 'Pablo Picasso',\n",
       " 'Henri Matisse',\n",
       " 'Edgar Degas',\n",
       " 'Henri Rousseau',\n",
       " 'Vincent van Gogh',\n",
       " 'Rembrandt',\n",
       " 'Vincent van Gogh',\n",
       " 'Vincent van Gogh',\n",
       " 'Albrecht Du rer',\n",
       " 'Albrecht Du rer',\n",
       " 'Salvador Dali',\n",
       " 'Paul Gauguin',\n",
       " 'Edgar Degas',\n",
       " 'Pablo Picasso',\n",
       " 'Amedeo Modigliani',\n",
       " 'Edgar Degas',\n",
       " 'Vincent van Gogh',\n",
       " 'Mikhail Vrubel',\n",
       " 'Mikhail Vrubel',\n",
       " 'Vincent van Gogh',\n",
       " 'Edgar Degas',\n",
       " 'Pablo Picasso',\n",
       " 'Salvador Dali',\n",
       " 'Pierre-Auguste Renoir',\n",
       " 'Alfred Sisley',\n",
       " 'Paul Gauguin',\n",
       " 'Edvard Munch',\n",
       " 'Raphael',\n",
       " ...]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_label = [ new_labels[i] for i in predict ]\n",
    "predict_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eeae18fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T08:29:05.549784Z",
     "start_time": "2022-11-08T08:29:05.541256Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00000</td>\n",
       "      <td>Edgar Degas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00001</td>\n",
       "      <td>Amedeo Modigliani</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00002</td>\n",
       "      <td>Caravaggio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_00003</td>\n",
       "      <td>Albrecht Du rer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_00004</td>\n",
       "      <td>Vincent van Gogh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             artist\n",
       "0  TEST_00000        Edgar Degas\n",
       "1  TEST_00001  Amedeo Modigliani\n",
       "2  TEST_00002         Caravaggio\n",
       "3  TEST_00003    Albrecht Du rer\n",
       "4  TEST_00004   Vincent van Gogh"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submisson['artist'] = predict_label\n",
    "submisson.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f4ad91d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T08:29:08.814492Z",
     "start_time": "2022-11-08T08:29:08.407412Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "submisson['artist'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d04381cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T08:29:18.453172Z",
     "start_time": "2022-11-08T08:29:18.444922Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vincent van Gogh             1452\n",
       "Edgar Degas                  1092\n",
       "Pablo Picasso                 750\n",
       "Albrecht Du rer               560\n",
       "Pierre-Auguste Renoir         524\n",
       "Alfred Sisley                 493\n",
       "Francisco Goya                432\n",
       "Titian                        424\n",
       "Paul Gauguin                  421\n",
       "Rembrandt                     389\n",
       "Amedeo Modigliani             359\n",
       "Henri Matisse                 327\n",
       "Marc Chagall                  295\n",
       "Rene Magritte                 287\n",
       "Peter Paul Rubens             251\n",
       "Mikhail Vrubel                245\n",
       "Giotto di Bondone             243\n",
       "Sandro Botticelli             237\n",
       "Pieter Bruegel                232\n",
       "Andy Warhol                   229\n",
       "Paul Klee                     195\n",
       "Salvador Dali                 192\n",
       "Frida Kahlo                   190\n",
       "Raphael                       183\n",
       "Diego Velazquez               175\n",
       "Kazimir Malevich              175\n",
       "Edouard Manet                 165\n",
       "Gustav Klimt                  151\n",
       "Leonardo da Vinci             148\n",
       "El Greco                      147\n",
       "Hieronymus Bosch              142\n",
       "Diego Rivera                  141\n",
       "Andrei Rublev                 118\n",
       "Joan Miro                     117\n",
       "Vasiliy Kandinskiy            111\n",
       "William Turner                102\n",
       "Piet Mondrian                 101\n",
       "Edvard Munch                   96\n",
       "Camille Pissarro               90\n",
       "Caravaggio                     88\n",
       "Henri Rousseau                 85\n",
       "Claude Monet                   83\n",
       "Michelangelo                   76\n",
       "Jan van Eyck                   75\n",
       "Georges Seurat                 75\n",
       "Henri de Toulouse-Lautrec      71\n",
       "Paul Cezanne                   54\n",
       "Gustave Courbet                48\n",
       "Eugene Delacroix               17\n",
       "Jackson Pollock                17\n",
       "Name: artist, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submisson['artist'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4438d3c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T08:29:21.521910Z",
     "start_time": "2022-11-08T08:29:21.515402Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(submisson['artist'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0c6cf6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T08:29:22.759391Z",
     "start_time": "2022-11-08T08:29:22.743741Z"
    }
   },
   "outputs": [],
   "source": [
    "submisson.to_csv(base_path+'/submit_EfficientNetB0_B3_4fold_raw_2_4_221108.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c027f31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "460.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
